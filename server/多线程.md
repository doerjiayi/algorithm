
##多线程博客
https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/5950400.html
https://blog.csdn.net/chenjiayi_yun/article/details/43938623
https://blog.csdn.net/chenjiayi_yun/article/details/40427141
https://blog.csdn.net/qq_43401808/article/details/86540962
https://blog.csdn.net/chenjiayi_yun/article/details/19023135

https://www.e-learn.cn/content/qita/1141137
https://www.cnblogs.com/fudong071234/p/6759567.html
https://www.jianshu.com/p/6f5c38da6430
https://www.cnblogs.com/liang1101/p/7285955.html

https://blog.csdn.net/longbei9029/article/details/60956892

##线程内存模型
###C/C++并发编程（1）—— 并发/并行、多线程内存模型
https://www.jianshu.com/p/298296e9a887
为了在性能和易编程性之间找到平衡，C++11提出了“sequential consistency for data race free programs”内存模型，即没有数据竞跑（data race）的程序符合顺序一致性。数据竞跑是指多个线程在没有同步的情况下去访问相同的内存位置[5]。所以，在C11/C++11后，我们只要对多线程之间需要同步的变量和操作，使用正确的同步原语进行同步，就能保证程序的执行符合顺序一致性。编译器、多核CPU能保证其优化措施不会破坏顺序一致性。

另外，C11/C++11标准还明确了“内存位置”的定义。

一个内存位置要么是标量，要么是一组紧邻的具有非零长度的位域。
两个线程可以互不干扰地对不同的内存位置进行读写操作

比如有如下的结构体：

struct
{
int a : 17;
int b : 15;
} x;
两个线程分别读写a和b，是否会互相干扰呢？毕竟CPU是按32/64位来取操作数的，而不是按17/15位来的。C11/C++11之前这样的操作是未定义的，按C11/C++标准规定a和b则属于同一个内存位置。两个线程分别对a、b进行读写操作是会相互干扰的，需要进行同步。或者将a、b分割成两个内存位置：

struct
{
int a : 17;    // 内存位置1
int : 0;
int b : 15;    // 内存位置2
} x;
这样编译器会自动自行内存对齐，保证两个线程分别读写a、b互不干扰。


https://blog.csdn.net/qq_40273354/article/details/78494504

###线程局部存储(thread_local)
https://www.jianshu.com/p/8df45004bbcb

线程局部存储在其它语言中都是以库的形式提供的(库函数或类)。但在C++11中以关键字的形式，做为一种存储类型出现，由此可见C++11对线程局部存储的重视。
 
thread_local修饰的变量具有如下特性:

变量在线程创建时生成(不同编译器实现略有差异，但在线程内变量第一次使用前必然已构造完毕)。
线程结束时被销毁(析构，利用析构特性，thread_local变量可以感知线程销毁事件)。
每个线程都拥有其自己的变量副本。
thread_local可以和static或extern联合使用，这将会影响变量的链接属性。


下面代码演示了thread_local变量在线程中的生命周期

// thread_local.cpp

class A {
public:
  A() {
    std::cout << std::this_thread::get_id()
              << " " << __FUNCTION__
              << "(" << (void *)this << ")"
              << std::endl;
  }

  ~A() {
    std::cout << std::this_thread::get_id()
              << " " << __FUNCTION__
              << "(" << (void *)this << ")"
              << std::endl;
  }

  // 线程中，第一次使用前初始化
  void doSth() {
  }
};

thread_local A a;

int main() {
  a.doSth();
  std::thread t([]() {
    std::cout << "Thread: "
              << std::this_thread::get_id()
              << " entered" << std::endl;
    a.doSth();
  });

  t.join();

  return 0;
}
运行该程序

$> g++ -std=c++11 -o debug/tls.out ./thread_local.cpp
$> ./debug/tls.out
01 A(0xc00720)
Thread: 02 entered
02 A(0xc02ee0)
02 ~A(0xc02ee0)
01 ~A(0xc00720)
$>
变量a在main线程和t线程中分别保留了一份副本，以下时序图表明了两份副本的生命周期。


https://blog.csdn.net/y396397735/article/details/81271339
https://blog.csdn.net/woshi_caibi/article/details/71124390


##线程性能
###创建多少个线程合适
https://www.jianshu.com/p/f30ee2346f9f
对于 CPU 密集型来说，理论上 线程数量 = CPU 核数（逻辑）就可以了，但是实际上，数量一般会设置为 CPU 核数（逻辑）+ 1， 为什么呢？

《Java并发编程实战》这么说：

计算(CPU)密集型的线程恰好在某时因为发生一个页错误或者因其他原因而暂停，刚好有一个“额外”的线程，可以确保在这种情况下CPU周期不会中断工作。

所以对于CPU密集型程序， CPU 核数（逻辑）+ 1 个线程数是比较好的经验值的原因了

I/O密集型程序创建多少个线程合适？
这是一个CPU核心的最佳线程数，如果多个核心，那么 I/O 密集型程序的最佳线程数就是：

最佳线程数 = CPU核心数 * (1/CPU利用率) = CPU核心数 * (1 + (I/O耗时/CPU耗时))

要计算 I/O 密集型程序，是要知道 CPU 利用率的，如果我不知道这些，那要怎样给出一个初始值呢？

按照上面公式，假如几乎全是 I/O耗时，所以纯理论你就可以说是 2N（N=CPU核数），当然也有说 2N + 1的，（我猜这个 1 也是 backup）

 如果理论都好用，那就用不着实践了，也就更不会有调优的事出现了。不过在初始阶段，我们确实可以按照这个理论之作为伪标准， 毕竟差也可能不会差太多，这样调优也会更好一些

谈完理论，咱们说点实际的，公式我看懂了（定性阶段结束），但是我有两个疑问：

我怎么知道具体的 I/O耗时和CPU耗时呢？
怎么查看CPU利用率？
没错，我们需要定量分析了

 有很多 APM （Application Performance Manager）工具可以帮我们得到准确的数据，学会使用这类工具，也就可以结合理论，在调优的过程得到更优的线程个数了。我这里简单列举几个，具体使用哪一个，具体应用还需要你自己去调研选择，受篇幅限制，暂不展开讨论了

SkyWalking
CAT
zipkin

小问二
计算操作需要5ms，DB操作需要 100ms，对于一台 8个CPU的服务器，怎么设置线程数呢？

如果不知道请拿三年级期末考试题重新做（今天晚自习留下来），答案是：

线程数 = 8 * (1 + 100/5) = 168 (个)

总结
多线程不一定就比单线程高效，比如大名鼎鼎的 Redis （后面会分析），因为它是基于内存操作，这种情况下，单线程可以很高效的利用CPU。而多线程的使用场景一般时存在相当比例的I/O或网络操作

另外，结合小学数学题，我们已经了解了如何从定性到定量的分析的过程，在开始没有任何数据之前，我们可以使用上文提到的经验值作为一个伪标准，其次就是结合实际来逐步的调优（综合 CPU，内存，硬盘读写速度，网络状况等）了

##线程同步
###条件变量 condition_variable
http://www.cplusplus.com/reference/condition_variable/condition_variable/
http://www.cplusplus.com/reference/condition_variable/condition_variable/notify_all/
http://www.cplusplus.com/reference/condition_variable/condition_variable_any/
https://www.cnblogs.com/huty/p/8516997.html

###linux 多线程的线程控制和线程通信
https://blog.csdn.net/chenjiayi_yun/article/details/18059665
1、Linux 线程概念
     进程与线程之间是有区别的，不过Linux内核只提供了轻量进程的支持，而其所谓的线程本质上在内核里仍然是进程。

     进程是资源分配的单位，同一进程中的多个线程共享该进程的资源。Linux中的线程只是在被创建时clone了父进程的资源，因此clone出来的进程表现为线程，只是它有共享父进程资源的特性。

   程序与线程库相链接即可支持Linux平台上的多线程，在程序中需包含头文件pthread. h，在编译链接时使用命令： 
gcc -D -REENTRANT -lpthread xxx. c

其中-REENTRANT宏使得相关库函数(如stdio.h、errno.h中函数) 是可重入的、线程安全的(thread-safe)，-lpthread则意味着链接库目录下的libpthread.a或libpthread.so文件。

流行的线程模型有LinuxThreads 和 NPTL。使用线程库需要2.0以上版本的Linux内核,及相应版本的C库(libc 或glibc )。

参考：http://www.ibm.com/developerworks/cn/linux/l-threading.html

2、线程控制 
（1）线程创建 

进程被创建时，系统会为其创建一个主线程，而要在进程中创建新的线程，则可以调用pthread_create： 
pthread_create(pthread_t *thread, const pthread_attr_t *attr, void * (start_routine)(void*), void *arg);


start_routine为新线程的入口函数，arg为传递给start_routine的参数。 

每个线程都有自己的线程ID，以便在进程内区分。线程ID在pthread_create调用时回返给创建线程的调用者；一个线程也可以在创建后使用pthread_self()调用获取自己的线程ID： 

pthread_self (void) ;


（2）线程退出 

线程的退出方式： 

1）执行完成后隐式退出
2）由线程本身显示调用pthread_exit 函数退出
pthread_exit (void * retval) ;

3）被其他线程用pthread_cance函数终止

pthread_cance (pthread_t thread) ;


在某线程中调用此函数，可以终止由参数thread 指定的线程。 

如果一个线程要等待另一个线程的终止，可以使用pthread_join函数，该函数的作用是调用pthread_join的线程将被挂起直到线程ID为参数thread的线程终止： 

pthread_join (pthread_t thread, void** threadreturn);

3、线程通信 
（1）线程互斥 

互斥意味着“排它”，即两个线程不能同时进入被互斥保护的代码。Linux下可以通过pthread_mutex_t 定义互斥体机制完成多线程的互斥操作，该机制的作用是对某个需要互斥的部分，在进入时先得到互斥体，如果没有得到互斥体，表明互斥部分被其它线程拥有，此时欲获取互斥体的线程阻塞，直到拥有该互斥体的线程完成互斥部分的操作为止。 

下面的代码实现了对共享全局变量x1 用互斥体mutex 进行保护的目的： 
int x1; // 进程中的全局变量 
pthread_mutex_t mutex; 
pthread_mutex_init(&mutex, NULL); //按缺省的属性初始化互斥体变量mutex 
pthread_mutex_lock(&mutex); // 给互斥体变量加锁 
… //对变量x1 的操作 
phtread_mutex_unlock(&mutex); // 给互斥体变量解除锁


（2）线程同步 

同步就是线程等待某个事件的发生。只有当等待的事件发生线程才继续执行，否则线程挂起并放弃处理器。当多个线程协作时，相互作用的任务必须在一定的条件下同步。 
1）条件变量

Linux下的C语言编程有多种线程同步机制，最典型的是条件变量(condition variable)。

pthread_cond_init用来创建一个条件变量，其函数原型为： 

pthread_cond_init (pthread_cond_t *cond, const pthread_condattr_t *attr);


pthread_cond_wait和pthread_cond_timedwait用来等待条件变量被设置，值得注意的是这两个等待调用需要一个已经上锁的互斥体mutex，这是为了防止在真正进入等待状态之前别的线程有可能设置该条件变量而产生竞争。

pthread_cond_wait的函数原型为： 

pthread_cond_wait (pthread_cond_t *cond, pthread_mutex_t *mutex);


pthread_cond_broadcast用于设置条件变量，即使得事件发生，这样等待该事件的线程将不再阻塞： 

pthread_cond_broadcast (pthread_cond_t *cond) ;

pthread_cond_signal则用于解除某一个等待线程的阻塞状态： 

pthread_cond_signal (pthread_cond_t *cond) ;


pthread_cond_destroy(pthread_cond_t *cond)  则用于释放一个条件变量的资源。 

pthread_cond_destroy(pthread_cond_t *cond) ；



pthread_cond_timedwait 计时等待方式

int pthread_cond_timedwait(pthread_cond_t *cond, pthread_mutex_t *mutex, const struct timespec *abstime);

如果在给定时刻前条件没有满足，则返回ETIMEOUT，结束等待，其中abstime以与time()系统调用相同意义的绝对时间形式出现，0表示格林尼治时间1970年1月1日0时0分0秒。



pthread_cond_timedwait 和pthread_cond_wait，都必须和一个互斥锁配合，以防止多个线程同时请求pthread_cond_wait()（或pthread_cond_timedwait()，下同）的竞争条件（Race Condition）。mutex互斥锁必须是普通锁（PTHREAD_MUTEX_TIMED_NP）或者适应锁（PTHREAD_MUTEX_ADAPTIVE_NP），且在调用pthread_cond_wait()前必须由本线程加锁（pthread_mutex_lock()），而在更新条件等待队列以前，mutex保持锁定状态，并在线程挂起进入等待前解锁。在条件满足从而离开pthread_cond_wait()之前，mutex将被重新加锁，以与进入pthread_cond_wait()前的加锁动作对应。
激发条件有两种形式，pthread_cond_signal()激活一个等待该条件的线程，存在多个等待线程时按入队顺序激活其中一个；而pthread_cond_broadcast()则激活所有等待线程。


###读写锁
https://www.cnblogs.com/i80386/p/4478021.html
https://www.cnblogs.com/i80386/p/4478021.html
https://www.cnblogs.com/defen/p/4410232.html
https://blog.csdn.net/yand789/article/details/27324295

###atomic 和 cas

####std::atomic::exchange
http://www.cplusplus.com/reference/atomic/atomic/exchange/

T exchange (T val, memory_order sync = memory_order_seq_cst) volatile noexcept;
T exchange (T val, memory_order sync = memory_order_seq_cst) noexcept;
Access and modify contained value
Replaces the contained value by val and returns the value it had immediately before.


Example 
std::atomic<bool> ready (false);
std::atomic<bool> winner (false);

void count1m (int id) {
  while (!ready) {}                  // wait for the ready signal
  for (int i=0; i<1000000; ++i) {}   // go!, count to 1 million
  if (!winner.exchange(true)) { std::cout << "thread #" << id << " won!\n"; }
};

int main ()
{
  std::vector<std::thread> threads;
  std::cout << "spawning 10 threads that count to 1 million...\n";
  for (int i=1; i<=10; ++i) threads.push_back(std::thread(count1m,i));
  ready = true;
  for (auto& th : threads) th.join();

  return 0;
}
 Edit & Run


Possible output (other threads may win):
spawning 10 threads that count to 1 million...
thread #7 won!

https://blog.csdn.net/FreeeLinux/article/details/53695111
https://www.cnblogs.com/dengzz/p/5686866.html

####gcc 原子操作函数
https://blog.csdn.net/chenjiayi_yun/article/details/16333779

1、原子操作的api函数
（1）直接操作数的原子操作
第一组返回更新前的值，第二组返回更新后的值

type __sync_fetch_and_add (type *ptr, type value, ...)
type __sync_fetch_and_sub (type *ptr, type value, ...)
type __sync_fetch_and_or (type *ptr, type value, ...)
type __sync_fetch_and_and (type *ptr, type value, ...)
type __sync_fetch_and_xor (type *ptr, type value, ...)
type __sync_fetch_and_nand (type *ptr, type value, ...)

type __sync_add_and_fetch (type *ptr, type value, ...)
type __sync_sub_and_fetch (type *ptr, type value, ...)
type __sync_or_and_fetch (type *ptr, type value, ...)
type __sync_and_and_fetch (type *ptr, type value, ...)
type __sync_xor_and_fetch (type *ptr, type value, ...)
type __sync_nand_and_fetch (type *ptr, type value, ...)

type可以是1,2,4或8字节长度的int类型，即：

int8_t / uint8_t
int16_t / uint16_t
int32_t / uint32_t
int64_t / uint64_t
 

后面的可扩展参数(...)用来指出哪些变量需要memory barrier,因为目前gcc实现的是full barrier（类似于linux kernel 中的mb(),表示这个操作之前的所有内存操作不会被重排序到这个操作之后）,所以可以略掉这个参数。

（2）比较后操作数的原子操作
bool __sync_bool_compare_and_swap (type *ptr, type oldval type newval, ...)
type __sync_val_compare_and_swap (type *ptr, type oldval type newval, ...)


这两个函数提供原子的比较和交换，如果*ptr == oldval,就将newval写入*ptr,
第一个函数在相等并写入的情况下返回true.
第二个函数在返回操作之前的值。
 
(3)其他原子操作
type __sync_lock_test_and_set (type *ptr, type value, ...)
   将*ptr设为value并返回*ptr操作之前的值。

void __sync_lock_release (type *ptr, ...)
     将*ptr置0

##多线程使用技巧
###线程池
https://github.com/lzpong/threadpool/blob/master/threadpool.h

###c++多线程编程：常见面试题
https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/5950400.html

####子线程和主线程循环   condition_variable.wait  cond.notify_one mutex
题目：子线程循环 10 次，接着主线程循环 100 次，接着又回到子线程循环 10 次，接着再回到主线程又循环 100 次，如此循环50次，试写出代码

子线程与主线程必有一个满足条件(flag == num),不满足条件的那个线程不可能获取unique_lock(会在wait中释放)，只有满足条件的线程才能获取锁，执行程序

mutex m;//保护条件的互斥访问
condition_variable cond;//条件变量
int flag = 10;//条件
void fun(int num) {
    for (int i = 0; i<50; i++) {
        unique_lock<mutex> lk(m);//A unique lock is an object that manages a mutex object with unique ownership in both states: locked and unlocked.  
        while (flag != num)
            cond.wait(lk);//在调用wait时会执行lk.unlock()  
        for (int j = 0; j<num; j++)
            cout << j << " ";
        cout << endl;
        flag = (num == 10) ? 100 : 10;
        cond.notify_one();//被阻塞的线程唤醒后lk.lock()恢复在调用wait前的状态  
    }
}
int main() {
    thread child(fun, 10);
    fun(100);
    child.join();
    system("pause");
    return 0;
}

####3个线程打印 condition_variable.wait notify_all mutex
题目：编写一个程序，开启3个线程，这3个线程的ID分别为A、B、C，每个线程将自己的ID在屏幕上打印10遍，要求输出结果必须按ABC的顺序显示；如：ABCABC….依次递推。

mutex m;
condition_variable cond;
int loop = 10;
int flag = 0;

void func(int id)
{
    for (int i = 0; i < loop; ++i)
    {
        unique_lock<mutex> lk(m);
        while (flag != id)
            cond.wait(lk);
        cout << static_cast<char>('A' + id) << " ";
        flag = (flag + 1) % 3;
        cond.notify_all();
    }
}

void main()
{
    thread A(func, 0);
    thread B(func, 1);
    func(2);
    cout << endl;
    A.join();
    B.join();
    system("pause");
}

####四个线程输出 condition_variable wait notify_all mutex
题目(google笔试题)：有四个线程1、2、3、4。线程1的功能就是输出1，线程2的功能就是输出2，以此类推.........现在有四个文件ABCD。初始都为空。现要让四个文件呈如下格式：
A：1 2 3 4 1 2....
B：2 3 4 1 2 3....
C：3 4 1 2 3 4....

D：4 1 2 3 4 1....

mutex m;
condition_variable cond;
int loop = 10;
int flag;

void func(int num)
{
    for (int i = 0; i < loop; ++i)
    {
        unique_lock<mutex> lk(m);
        while (num != flag)
            cond.wait(lk);
        cout << num + 1 << " ";
        flag = (flag + 1) % 4;
        cond.notify_all();
    }
}

void main(int argc,char *argv[])
{
    flag = atoi(argv[1]);
    thread one(func, 1);
    thread two(func, 2);
    thread three(func, 3);
    func(0);
    one.join();
    two.join();
    three.join();
    cout << endl;
    system("pause");
}

####读者写者问题

这也是一个非常经典的多线程题目，题目大意如下：有一个写者很多读者，多个读者可以同时读文件，但写者在写文件时不允许有读者在读文件，同样有读者读时写者也不能写。

class rwlock {
private:
    mutex _lock;
    condition_variable _wcon, _rcon;
    unsigned _writer, _reader;
    int _active;
public:
    void read_lock() {
        unique_lock<mutex> lock(_lock);
        ++_reader;
        while (_active < 0 || _writer > 0)
            _rcon.wait(lock);
        --_reader;
        ++_active;
    }
    void write_lock() {
        unique_lock<mutex> lock(_lock);
        ++_writer;
        while (_active != 0)
            _wcon.wait(lock);
        --_writer;
        _active = -1;
    }
    void unlock() {
        unique_lock<mutex> lock(_lock);
        if (_active > 0) {
            --_active;
            if (_active == 0) _wcon.notify_one();
        }
        else {
            _active = 0;
            if (_writer > 0) _wcon.notify_one();
            else if (_reader > 0) _rcon.notify_all();
        }
    }
    rwlock() :_writer(0), _reader(0), _active(0) {
    }
};

void t1(rwlock* rwl) {
    while (1) {
        cout << "I want to write." << endl;
        rwl->write_lock();
        cout << "writing..." << endl;
        this_thread::sleep_for(chrono::seconds(5));
        rwl->unlock();
        this_thread::sleep_for(chrono::seconds(5));
    }
}

void t2(rwlock* rwl) {
    while (1) {
        cout << "t2-I want to read." << endl;
        rwl->read_lock();
        cout << "t2-reading..." << endl;
        this_thread::sleep_for(chrono::seconds(1));
        rwl->unlock();
    }
}

void t3(rwlock* rwl) {
    while (1) {
        cout << "t3-I want to read." << endl;
        rwl->read_lock();
        cout << "t3-reading..." << endl;
        this_thread::sleep_for(chrono::seconds(1));
        rwl->unlock();
    }
}

int main()
{
    rwlock* rwl = new rwlock();
    thread th1(t1, rwl);
    thread th2(t2, rwl);
    thread th3(t3, rwl);
    th1.join();
    th2.join();
    th3.join();
    system("pause");
    return 0;
}
 

####线程安全的queue condition_variable std::lock_guard<std::mutex>

STL中的queue是非线程安全的，一个组合操作：front(); pop()先读取队首元素然后删除队首元素，若是有多个线程执行这个组合操作的话，可能会发生执行序列交替执行，导致一些意想不到的行为。因此需要重新设计线程安全的queue的接口。

复制代码
template<typename T>
class threadsafe_queue
{
private:
    mutable std::mutex mut;
    std::queue<T> data_queue;
    std::condition_variable data_cond;
public:
    threadsafe_queue() {}
    threadsafe_queue(threadsafe_queue const& other)
    {
        std::lock_guard<std::mutex> lk(other.mut);
        data_queue = other.data_queue;
    }
    void push(T new_value)//入队操作  
    {
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(new_value);
        data_cond.notify_one();
    }
    void wait_and_pop(T& value)//直到有元素可以删除为止  
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk, [this] {return !data_queue.empty(); });
        value = data_queue.front();
        data_queue.pop();
    }
    std::shared_ptr<T> wait_and_pop()
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk, [this] {return !data_queue.empty(); });
        std::shared_ptr<T> res(std::make_shared<T>(data_queue.front()));
        data_queue.pop();
        return res;
    }
    bool try_pop(T& value)//不管有没有队首元素直接返回  
    {
        std::lock_guard<std::mutex> lk(mut);
        if (data_queue.empty())
            return false;
        value = data_queue.front();
        data_queue.pop();
        return true;
    }
    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lk(mut);
        if (data_queue.empty())
            return std::shared_ptr<T>();
        std::shared_ptr<T> res(std::make_shared<T>(data_queue.front()));
        data_queue.pop();
        return res;
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lk(mut);
        return data_queue.empty();
    }
};

####atomic promise future
题目：编写程序完成如下功能：

1）有一int型全局变量g_Flag初始值为0
2） 在主线称中起动线程1，打印“this is thread1”，并将g_Flag设置为1
3） 在主线称中启动线程2，打印“this is thread2”，并将g_Flag设置为2
4） 线程序1需要在线程2退出后才能退出
5） 主线程在检测到g_Flag从1变为2，或者从2变为1的时候退出

atomic<int> flag(0);

void worker1(future<int> fut) 
{//线程1  
    printf("this is thread1\n");
    flag = 1;
    fut.get();//线程1阻塞至线程2设置共享状态  get等待异步操作结束并返回结果
    printf("thread1 exit\n");
}

void worker2(promise<int> prom) 
{//线程2  
    printf("this is thread2\n");//C++11的线程输出cout没有boost的好，还是会出现乱序，所以采用printf，有点不爽  
    flag = 2;
    prom.set_value(10);//线程2设置了共享状态后，线程1才会被唤醒  
    printf("thread2 exit\n");
}

//利用promise future来控制线程退出的次序
int main()
{
    promise<int> prom;
    future<int> fut = prom.get_future();
    thread one(worker1, move(fut));//注意future和promise不允许拷贝，但是具备move语义  
    thread two(worker2, move(prom));
    while (flag.load() == 0);
　　///将本线程从调用线程中分离出来，允许本线程独立执行
    one.detach();
    two.detach();
    //exit(1);//主线程到这里退出  
    printf("main thread exit\n");
    system("pause");
    return 0;
}