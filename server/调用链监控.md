
#调用链选型之Zipkin，Pinpoint，SkyWalking，CAT
https://www.jianshu.com/p/0fbbf99a236e

#cat
https://github.com/dianping/cat/

#GRPC java 分布式调用链跟踪实践
https://www.jianshu.com/p/2ec0f8d4ae3d

在跟踪链中有以下几个比较重要的数据结构和概念：
span：标识一次分布式调用，其自身包含了id，parentId(指向上级Span的id)， traceIds，服务名称等重要属性，其应尽量保持精简；
trace：标识整个请求链，即一些列Span的组合。其自身的ID将贯穿整个调用链，其中的每个Span都必须携带这个traceId，因此traceId将在整个调用链中传递；
cs：客户端发起请求，标志Span的开始；
sr：服务端接收到请求，并开始处理内部事务，其中sr - cs则为网络延迟和时钟抖动；
ss：服务端处理完请求，返回响应内容，其中ss - sr则为服务端处理请求耗时；
cr：客户端接收到服务端响应内容，标志着Span的结束，其中cr - ss则为网络延迟和时钟抖动。
客户端调用时间=cr-cs
服务端处理时间=sr-ss

#OpenTracing
https://www.jianshu.com/p/d2b11c079af0
https://studygolang.com/articles/13583


##OpenTracing语义标准规范及实现
https://www.jianshu.com/p/a963ad0bbe3e
注：本文转自好友吴晟的两篇译文 ，译文原文如下：
https://github.com/opentracing-contrib/opentracing-specification-zh/blob/master/semantic_conventions.md
https://github.com/opentracing-contrib/opentracing-specification-zh/blob/master/specification.md

一、 前言
什么是OpenTracing?
OpenTracing(http://opentracing.io/)是分布式跟踪系统，当我们把系统拆成服务化，分布式系统的时候，查询一个问题，很可能需要多个登录多台机器。
OpenTracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。OpenTracing正在为全球的分布式追踪，提供统一的概念和数据标准。
关于OpenTracing的一个Java版本的实现请参考如下代码：
https://github.com/opentracing/opentracing-java

二、语义惯例
OpenTracing标准 描述的语言无关的数据模型，以及OpenTracing API的使用方法。在此数据模型中，包含了两个相关的概念 Span Tag 和 (结构化的) Log Field，尽管在标准中，已经明确了这些操作，但没有定义Span的tag和logging操作时，key的使用规范。
这些语义习惯通过这篇文档进行描述。这篇文档包括两个部分：一. 通过表格罗列出所有的tag和logging操作时，标准的key值。二.描述在特定的典型场景中，如何组合使用这些标准的key值，进行建模。
版本命名策略
修改此文件，将影响到OpenTracing标准的版本号。增加内容会增加小版本号，不向前兼容的改变（或新增大量内容）会增加大版本号。
标准的Span tag 和 log field
Span tag 清单
Span的tag作用于 整个Span，也就是说，它会覆盖Span的整个事件周期，所以无需指定特别的时间戳。对于由时间点特性的事件，最好使用Span的log操作进行记录。（在本文档的下一章中进行描述）。
Span tag 名称
类型
描述与实例
component
string
生成此Span所相关的软件包，框架，类库或模块。如 "grpc", "django", "JDBI".
db.instance
string
数据库实例名称。以Java为例，如果 jdbc.url="jdbc:mysql://127.0.0.1:3306/customers"，实例名为 "customers".
db.statement
string
一个针对给定数据库类型的数据库访问语句。例如， 针对数据库类型 db.type="sql"，语句可能是 "SELECT * FROM wuser_table"; 针对数据库类型为 db.type="redis"，语句可能是 "SET mykey 'WuValue'".
db.type
string
数据库类型。对于任何支持SQL的数据库，取值为 "sql". 否则，使用小写的数据类型名称，如 "cassandra", "hbase", or "redis".
db.user
string
访问数据库的用户名。如 "readonly_user" 或 "reporting_user" 
error
bool
设置为true，说明整个Span失败。译者注：Span内发生异常不等于error=true，这里由被监控的应用系统决定
http.method
string
Span相关的HTTP请求方法。例如 "GET", "POST" 
http.status_code
integer
Span相关的HTTP返回码。例如 200, 503, 404
http.url
string
被处理的trace片段锁对应的请求URL。 例如 "https://domain.net/path/to?resource=here" 
message_bus.destination
string
消息投递或交换的地址。例如，在Kafka中，在生产者或消费者两端，可以使用此tag来存储"topic name"。
peer.address
string
远程地址。 适合在网络调用的客户端使用。存储的内容可能是"ip:port"， "hostname"，域名，甚至是一个JDBC的连接串，如 "mysql://prod-db:3306" 
peer.hostname
string
远端主机名。例如 "opentracing.io", "internal.dns.name" 
peer.ipv4
string
远端 IPv4 地址，使用 . 分隔。例如 "127.0.0.1" 
peer.ipv6
string
远程 IPv6 地址，使用冒号分隔的元祖，每个元素为4位16进制数。例如 "2001:0db8:85a3:0000:0000:8a2e:0370:7334" 
peer.port
integer
远程端口。如 80 
peer.service
string
远程服务名（针对没有被标准化定义的"service"）。例如 "elasticsearch", "a_custom_microservice", "memcache" 
sampling.priority
integer
如果大于0，Tracer实现应该尽可能捕捉这个调用链。如果等于0，则表示不需要捕捉此调用链。如不存在，Tracer使用自己默认的采样机制。
span.kind
string
基于RPC的调用角色，"client" 或 "server". 基于消息的调用角色，"producer" 或 "consumer" 
Log field 清单
每个Span的log操作，都具有一个特定的时间戳（这个时间戳必须在Span的开始时间和结束时间之间），并包含一个或多个 field。下面是标准的field。
Span log field 名称
类型
描述和实例
error.kind
string
错误类型（仅在event="error"时使用）。如 "Exception", "OSError" 
error.object
object
如果当前语言支持异常对象（如 Java, Python），则为实际的Throwable/Exception/Error对象实例本身。例如 一个 java.lang.UnsupportedOperationException 实例, 一个python的 exceptions.NameError 实例
event
string
Span生命周期中，特定时刻的标识。例如，一个互斥锁的获取与释放，或 在Performance.timing 规范中描述的，浏览器页面加载过程中的各个事件。 还例如，Zipkin中 "cs", "sr", "ss", 或 "cr". 或者其他更抽象的 "initialized" 或 "timed out"。出现错误时，设置为 "error" 
message
string
简洁的，具有高可读性的一行事件描述。如 "Could not connect to backend", "Cache invalidation succeeded" 
stack
string
针对特定平台的栈信息描述，不强制要求与错误相关。如 "File \"example.py\", line 7, in \<module\>\ncaller()\nFile \"example.py\", line 5, in caller\ncallee()\nFile \"example.py\", line 2, in callee\nraise Exception(\"Yikes\")\n" 
典型场景建模
RPCs
使用下面tag为RPC调用建模：
span.kind: "client" 或 "server"。在Span开始时，设置此tag是十分重要的，它可能影响内部ID的生成。
error: RPC调用是否发生错误
peer.address, peer.hostname, peer.ipv4, peer.ipv6, peer.port, peer.service: 可选tag。描述RPC的对端信息。（一般只有在无法获取到这些信息时，才不设置这些值）
Message Bus
消息服务是一个异步调用，所以消费端的Span和生产端的Span使用 Follows From 关系。(查看 Span间关系)
使用下面tag为消息服务建模：
message_bus.destination: 上表已描述
span.kind: "producer" 或 "consumer". 建议 在span开始时 设置此tag，它可能影响内部ID的生成。
peer.address, peer.hostname, peer.ipv4, peer.ipv6, peer.port, peer.service: 可选tag，描述消息服务中broker的地址。（可能在内部无法获取）
Database (client) calls
使用下面tag为数据库客户端调用建模：
db.type, db.instance, db.user, 和 db.statement: 上表已描述
peer.address, peer.hostname, peer.ipv4, peer.ipv6, peer.port, peer.service: 描述数据库信息的可选tag
span.kind: "client" 
Captured errors，捕获错误
OpenTracing中，根据语言的不同，错误可以通过不同的方式来进行描述，有一些field是专门针对错误输出的，其他则不是（例如：event 或 message）
如果存在错误对象，它其中包含栈信息和错误信息，log时使用如下的field：
event="error" 
error.object=<error object instance> 
对于其他语言（译者注：不存在上述的错误对象），或上述操作不可行时：
event="error" 
message="..." 
stack="..." (可选)
error.kind="..." (可选)
通过此方案，Tracer实现可以在需要时，获取所需的错误信息。
三、OpenTracing语义标准
版本号: 1.1
综述
这是正式的OpenTracing语义标准。OpenTracing是一个跨编程语言的标准，此文档会避免具有语言特性的概念。比如，我们在文档中使用"interface"，因为所有的语言都包含"interface"这种概念。
版本命名策略
OpenTracing标准使用Major.Minor版本命名策略（即：大版本.小版本），但不包含.Patch版本（即：补丁版本）。如果标准做出不向前兼容的改变，则使用“主版本”号提升。如果是向前兼容的改进，则进行小版本号提升，例如加入新的标准tag, log和SpanContext引用类型。（如果你想知道更多关于制定此版本政策的原因，可参考specification#2）
OpenTracing数据模型
OpenTracing中的Trace（调用链）通过归属于此调用链的Span来隐性的定义。
特别说明，一条Trace（调用链）可以被认为是一个由多个Span组成的有向无环图（DAG图），
Span与Span的关系被命名为References。
译者注: Span，可以被翻译为跨度，可以被理解为一次方法调用, 一个程序块的调用, 或者一次RPC/数据库访问.只要是一个具有完整时间周期的程序访问，都可以被认为是一个span.在此译本中，为了便于理解，Span和其他标准内声明的词汇，全部不做名词翻译。
例如：下面的示例Trace就是由8个Span组成：
单个Trace中，span间的因果关系
        [Span A]  ←←←(the root span)
            |
     +------+------+
     |             |
 [Span B]      [Span C] ←←←(Span C 是 Span A 的孩子节点, ChildOf)
     |             |
 [Span D]      +---+-------+
               |           |
           [Span E]    [Span F] >>> [Span G] >>> [Span H]
                                       ↑
                                       ↑
                                       ↑
                         (Span G 在 Span F 后被调用, FollowsFrom)

有些时候，使用下面这种，基于时间轴的时序图可以更好的展现Trace（调用链）：
单个Trace中，span间的时间关系
––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–> time

 [Span A···················································]
   [Span B··············································]
      [Span D··········································]
    [Span C········································]
         [Span E·······]        [Span F··] [Span G··] [Span H··]

每个Span包含以下的状态:（译者注：由于这些状态会反映在OpenTracing API中，所以会保留部分英文说明）
An operation name，操作名称
A start timestamp，起始时间
A finish timestamp，结束时间
Span Tag，一组键值对构成的Span标签集合。键值对中，键必须为string，值可以是字符串，布尔，或者数字类型。
Span Log，一组span的日志集合。
每次log操作包含一个键值对，以及一个时间戳。
键值对中，键必须为string，值可以是任意类型。
但是需要注意，不是所有的支持OpenTracing的Tracer,都需要支持所有的值类型。
SpanContext，Span上下文对象 (下面会详细说明)
References(Span间关系)，相关的零个或者多个Span（Span间通过SpanContext建立这种关系）
每一个SpanContext包含以下状态：
任何一个OpenTracing的实现，都需要将当前调用链的状态（例如：trace和span的id），依赖一个独特的Span去跨进程边界传输
Baggage Items，Trace的随行数据，是一个键值对集合，它存在于trace中，也需要跨进程边界传输
Span间关系
一个Span可以与一个或者多个SpanContexts存在因果关系。OpenTracing目前定义了两种关系：ChildOf（父子） 和 FollowsFrom（跟随）。这两种关系明确的给出了两个父子关系的Span的因果模型。 将来，OpenTracing可能提供非因果关系的span间关系。（例如：span被批量处理，span被阻塞在同一个队列中，等等）。
ChildOf 引用: 一个span可能是一个父级span的孩子，即"ChildOf"关系。在"ChildOf"引用关系下，父级span某种程度上取决于子span。下面这些情况会构成"ChildOf"关系：
一个RPC调用的服务端的span，和RPC服务客户端的span构成ChildOf关系
一个sql insert操作的span，和ORM的save方法的span构成ChildOf关系
很多span可以并行工作（或者分布式工作）都可能是一个父级的span的子项，他会合并所有子span的执行结果，并在指定期限内返回
下面都是合理的表述一个"ChildOf"关系的父子节点关系的时序图。
    [-Parent Span---------]
         [-Child Span----]
    [-Parent Span--------------]
         [-Child Span A----]
          [-Child Span B----]
        [-Child Span C----]
         [-Child Span D---------------]
         [-Child Span E----]


FollowsFrom 引用: 一些父级节点不以任何方式依赖他们子节点的执行结果，这种情况下，我们说这些子span和父span之间是"FollowsFrom"的因果关系。"FollowsFrom"关系可以被分为很多不同的子类型，未来版本的OpenTracing中将正式的区分这些类型
下面都是合理的表述一个"FollowFrom"关系的父子节点关系的时序图。
    [-Parent Span-]  [-Child Span-]
    [-Parent Span--]
     [-Child Span-]
    [-Parent Span-]
                [-Child Span-]


OpenTracing API
OpenTracing标准中有三个重要的相互关联的类型，分别是Tracer, Span 和 SpanContext。下面，我们分别描述每种类型的行为，一般来说，每个行为都会在各语言实现层面上，会演变成一个方法，而实际上由于方法重载，很可能演变成一系列相似的方法。
当我们讨论“可选”参数时，需要强调的是，不同的语言针对可选参数有不同理解，概念和实现方式 。例如，在Go中，我们习惯使用"functional Options"，而在Java中，我们可能使用builder模式。
Tracer
Tracer接口用来创建Span，以及处理如何处理Inject(serialize) 和 Extract (deserialize)，用于跨进程边界传递。它具有如下官方能力：
创建一个新Span 
必填参数
operation name, 操作名, 一个具有可读性的字符串，代表这个span所做的工作（例如：RPC方法名，方法名，或者一个大型计算中的某个阶段或子任务）。操作名应该是一个抽象、通用，明确、具有统计意义的名称。因此，"get_user" 作为操作名，比 "get_user/314159"更好。
例如，假设一个获取账户信息的span会有如下可能的名称：
操作名
指导意见
get
太抽象
get_account/792
太明确
get_account
正确的操作名，关于account_id=792的信息应该使用Tag操作
可选参数
零个或者多个关联（references）的SpanContext，如果可能，同时快速指定关系类型，ChildOf 还是 FollowsFrom。
一个可选的显性传递的开始时间；如果忽略，当前时间被用作开始时间。
零个或者多个tag。
返回值，返回一个已经启动Span实例（已启动，但未结束。译者注：英语上started和finished理解容易混淆）
将SpanContext上下文Inject（注入）到carrier
必填参数
SpanContext实例
format（格式化）描述，一般会是一个字符串常量，但不做强制要求。通过此描述，通知Tracer实现，如何对SpanContext进行编码放入到carrier中。
carrier，根据format确定。Tracer实现根据format声明的格式，将SpanContext序列化到carrier对象中。
将SpanContext上下文从carrier中Extract（提取）
必填参数
format（格式化）描述，一般会是一个字符串常量，但不做强制要求。通过此描述，通知Tracer实现，如何从carrier中解码SpanContext。
carrier，根据format确定。Tracer实现根据format声明的格式，从carrier中解码SpanContext。
返回值，返回一个SpanContext实例，可以使用这个SpanContext实例，通过Tracer创建新的Span。
注意，对于Inject（注入）和Extract（提取），format是必须的。
Inject（注入）和Extract（提取）依赖于可扩展的format参数。format参数规定了另一个参数"carrier"的类型，同时约束了"carrier"中SpanContext是如何编码的。所有的Tracer实现，都必须支持下面的format。
Text Map: 基于字符串：字符串的map,对于key和value不约束字符集。
HTTP Headers: 适合作为HTTP头信息的，基于字符串：字符串的map。（RFC 7230.在工程实践中，如何处理HTTP头具有多样性，强烈建议tracer的使用者谨慎使用HTTP头的键值空间和转义符）
Binary: 一个简单的二进制大对象，记录SpanContext的信息。
Span
当Span结束后(span.finish())，除了通过Span获取SpanContext外，下列其他所有方法都不允许被调用。
除了通过Span获取SpanContext 
不需要任何参数。
返回值，Span构建时传入的SpanContext。这个返回值在Span结束后(span.finish())，依然可以使用。
复写操作名（operation name）
必填参数
新的操作名operation name，覆盖构建Span时，传入的操作名。
结束Span 
可选参数
一个明确的完成时间;如果省略此参数，使用当前时间作为完成时间。
为Span设置tag
必填参数
tag key，必须是string类型
tag value，类型为字符串，布尔或者数字
注意，OpenTracing标准包含"standard tags，标准Tag"，此文档中定义了Tag的标准含义。
Log结构化数据
必填参数
一个或者多个键值对，其中键必须是字符串类型，值可以是任意类型。某些OpenTracing实现，可能支持更多的log值类型。
可选参数
一个明确的时间戳。如果指定时间戳，那么它必须在span的开始和结束时间之内。
注意，OpenTracing标准包含"standard log keys，标准log的键"，此文档中定义了这些键的标准含义。
设置一个baggage（随行数据）元素
Baggage元素是一个键值对集合，将这些值设置给给定的Span，Span的SpanContext，以及所有和此Span有直接或者间接关系的本地Span。 也就是说，baggage元素随trace一起保持在带内传递。（译者注：带内传递，在这里指，随应用程序调用过程一起传递）
Baggage元素为OpenTracing的实现全栈集成，提供了强大的功能 （例如：任意的应用程序数据，可以在移动端创建它，显然的，它会一直传递了系统最底层的存储系统。由于它如此强大的功能，他也会产生巨大的开销，请小心使用此特性。
再次强调，请谨慎使用此特性。每一个键值都会被拷贝到每一个本地和远程的下级相关的span中，因此，总体上，他会有明显的网络和CPU开销。
必填参数
baggage key, 字符串类型
baggage value, 字符串类型
获取一个baggage元素
必填参数
baggage key, 字符串类型
返回值，相应的baggage value,或者可以标识元素值不存在的返回值（译者注：如Null）。
SpanContext
相对于OpenTracing中其他的功能，SpanContext更多的是一个“概念”。也就是说，OpenTracing实现中，需要重点考虑，并提供一套自己的API。
OpenTracing的使用者仅仅需要，在创建span、向传输协议Inject（注入）和从传输协议中Extract（提取）时，使用SpanContext和references，
OpenTracing要求，SpanContext是不可变的，目的是防止由于Span的结束和相互关系，造成的复杂生命周期问题。
遍历所有的baggage元素
遍历模型依赖于语言，实现方式可能不一致。在语义上，要求调用者可以通过给定的SpanContext实例，高效的遍历所有的baggage元素
NoopTracer
所有的OpenTracing API实现，必须提供某种方式的NoopTracer实现。NoopTracer可以被用作控制或者测试时，进行无害的inject注入（等等）。例如，在 OpenTracing-Java实现中，NoopTracer在他自己的模块中。
可选 API 元素
有些语言的OpenTracing实现，为了在串行处理中，传递活跃的Span或SpanContext，提供了一些工具类。例如，opentracing-go中，通过context.Context机制，可以设置和获取活跃的Span。


#Jaeger
## 分布式追踪OpenTracing与 Jaeger 实现  
https://github.com/jaegertracing/jaeger-client-cpp
https://blog.csdn.net/m0_37598953/article/details/88760603
https://www.kancloud.cn/idzqj/customer/1691930

##jaeger 使用初探
https://www.cnblogs.com/chopper-poet/p/10743141.html

##Linux下从零开始部署和使用Jaeger
https://www.jianshu.com/p/e224b5871998

##全链路监控Jaeger搭建实战
https://www.jianshu.com/p/ffc597bb4ce8

##基于jaeger微服务调用链实现方案
https://cloud.tencent.com/developer/article/1494063

#ZipKin
##ZipKin原理学习--ZipKin入门介绍
Zipkin是一款开源的分布式实时数据追踪系统（Distributed Tracking System），基于 Google Dapper的论文设计而来，由 Twitter 公司开发贡献。其主要功能是聚集来自各个异构系统的实时监控数据。分布式跟踪系统还有其他比较成熟的实现，例如：Naver的Pinpoint、Apache的HTrace、阿里的鹰眼Tracing、京东的Hydra、新浪的Watchman，美团点评的CAT，skywalking等。
ZipKin架构
    ZipKin可以分为两部分，一部分是zipkin server，用来作为数据的采集存储、数据分析与展示；zipkin client是zipkin基于不同的语言及框架封装的一些列客户端工具，这些工具完成了追踪数据的生成与上报功能

Zipkin Server主要包括四个模块：
（1）Collector 接收或收集各应用传输的数据
（2）Storage 存储接受或收集过来的数据，当前支持Memory，MySQL，Cassandra，ElasticSearch等，默认存储在内存中。
（3）API（Query） 负责查询Storage中存储的数据，提供简单的JSON API获取数据，主要提供给web UI使用
（4）Web 提供简单的web界面
 
 Instrumented client和server是分别使用了ZipKin Client的服务，Zipkin Client会根据配置将追踪数据发送到Zipkin  Server中进行数据存储、分析和展示。
ZipKin几个概念
    在追踪日志中，有几个基本概念spanId、traceId、parentId
    traceId：用来确定一个追踪链的16字符长度的字符串，在某个追踪链中保持不变。
    spanId：区域Id，在一个追踪链中spanId可能存在多个，每个spanId用于表明在某个服务中的身份，也是16字符长度的字符串。
    parentId：在跨服务调用者的spanId会传递给被调用者，被调用者会将调用者的spanId作为自己的parentId，然后自己再生成spanId。


##微服务调用链追踪中心搭建  ZIPKIN
https://www.jianshu.com/p/da80ea881424

##个推基于 Zipkin 的分布式链路追踪实践 
https://www.cnblogs.com/evakang/p/10951616.html

##ZIPKIN官网
https://zipkin.io/

##ZIPKIN github
https://github.com/openzipkin/zipkin

##ZIPKIN的搭建使用过程
https://blog.csdn.net/m15231417197/article/details/81540829
（描述可能不是很准确，多多包涵）zipkin类似于日志的高级版，跟踪监控,监控每一次请求链。
zipkin的一些理解：
cs   Client Send 客户端发起请求
sr   Server Receive 服务器接收请求，开始处理
ss   Server Send 服务器完成处理，给客户端应答
cr   Client Receive 客户端接受应答从服务器

traceId：标记一次请求的跟踪，相关的Spans都有相同的traceId；
id：span id；
name：span的名称，一般是接口方法的名称；
parentId：可选的id，当前Span的父Span id，通过parentId来保证Span之间的依赖关系，如果没有parentId，表示当前Span为根Span；
timestamp：Span创建时的时间戳，使用的单位是微秒（而不是毫秒），所有时间戳都有错误，包括主机之间的时钟偏差以及时间服务重新设置时钟的可能性，
出于这个原因，Span应尽可能记录其duration；
duration：持续时间使用的单位是微秒（而不是毫秒）；
annotations：注释用于及时记录事件；有一组核心注释用于定义RPC请求的开始和结束；

cs:Client Send，客户端发起请求；sr:Server Receive，服务器接受请求，开始处理；ss:Server Send，服务器完成处理，给客户端应答；cr:Client Receive，客户端接受应答从服务器；

binaryAnnotations：二进制注释，旨在提供有关RPC的额外信息。

其实就是描述了一次请求的详细信息这些，比如时间等，如果请求失败（报bug或者服务器当掉），就可以通过zipkin来查看请求是执行到了哪一台服务器后失败的，从而得知哪台服务器有问题或者是出bug了。

若要查看zipkin面板其他属性的含义可以查看此博客：
https://segmentfault.com/a/1190000012342007

此过程是使用idea创建的。
共需要创建四个项目：
eurekaserver      注册中心
zipkin-service     本文核心内容zipkin
product-service   服务提供
order-service       服务调用

##ZIPKIN
https://blog.csdn.net/qq_27384769/article/details/84965170

概述
zipkin为分布式链路调用监控系统，聚合各业务系统调用延迟数据，达到链路调用监控跟踪。
在复杂的调用链路中假设存在一条调用链路响应缓慢，如何定位其中延迟高的服务呢？
日志： 通过分析调用链路上的每个服务日志得到结果

zipkin：使用zipkin的web UI可以一眼看出延迟高的服务

zipkin
zipkin主要涉及四个组件 collector storage search web UI

Collector接收各service传输的数据
Cassandra作为Storage的一种，也可以是mysql等，默认存储在内存中，配置cassandra可以参考这里
Query负责查询Storage中存储的数据,提供简单的JSON API获取数据，主要提供给web UI使用

Web 提供简单的web界面

使用zipkin涉及几个概念

1. Span:基本工作单元，一次链路调用(可以是RPC，DB等没有特定的限制)创建一个span，通过一个64位ID标识它， 
span通过还有其他的数据，例如描述信息，时间戳，key-value对的(Annotation)tag信息，parent-id等,其中parent-id 
可以表示span调用链路来源，通俗的理解span就是一次请求信息

2. Trace:类似于树结构的Span集合，表示一条调用链路，存在唯一标识

3. Annotation: 注解,用来记录请求特定事件相关信息(例如时间)，通常包含四个注解信息

cs - Client Start,表示客户端发起请求
sr - Server Receive,表示服务端收到请求
ss - Server Send,表示服务端完成处理，并将结果发送给客户端
cr - Client Received,表示客户端获取到服务端返回信息

4. BinaryAnnotation:提供一些额外信息，一般已key-value对出现

##zipkin c/c++库编译及环境搭建
https://blog.csdn.net/upsuperman/article/details/78049411

##C++ opentracing zipkin 
https://www.cnblogs.com/resibe-3/p/8628561.html

github https://github.com/opentracing/opentracing-cpp
Compile and install
Linux/MacOS
mkdir .build
cd .build
cmake ..
make
sudo make install

make test

##ZipKin原理学习--ZipKin入门介绍
https://blog.csdn.net/qq924862077/article/details/80285536

##调用追踪存储展示应用——zipkin环境搭建
https://blog.csdn.net/upsuperman/article/details/78048972

##分布式跟踪系统（一）：Zipkin的背景和设计
https://blog.csdn.net/manzhizhen/article/details/52811600

##分布式跟踪系统（二）：Zipkin的Span模型
https://blog.csdn.net/manzhizhen/article/details/53865368?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-2

##zipkin trace数据结构说明（四） 
https://shared-code.com/article/105

##Zipkin 简单分析
https://blog.csdn.net/xsj34567/article/details/80939622

##ZIPKIN的搭建使用过程
https://blog.csdn.net/m15231417197/article/details/81540829

##SpringCloud微服务监控——zipkin：微服务链路跟踪
https://blog.csdn.net/fyk844645164/article/details/98746821

直接到官方地址下载相应的jar包就可以了。这里我下载的是zipkin-server-2.15.0-exec.jar。
编写启动脚本
在官方的文档中zipkin-server，介绍了如何配置。在这里，我们配置一个基于ELK的链路收集：
@echo off  
START "zipkin-server" java -Xmx256m -Xms256m -Xss256k -DKAFKA_BOOTSTRAP_SERVERS=192.168.xx.xxx:9092 -DSTORAGE_TYPE=elasticsearch -DES_HOSTS=192.168.xx.xxx:9200 -jar zipkin-server-2.15.0-exec.jar --server.port=9005
pause

客户端
引入jar包
在原有的spring boot项目中，引入jar包：
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

添加配置文件
在spring boot项目的application.properties文件中，加入配置：

将采样比例1.0是全部都采集，默认是0.1
spring.sleuth.sampler.probability=1.0
spring.zipkin.sender.type=kafka

zipkin里看到的的service name
spring.zipkin.service.name=${spring.application.name}

集群的情况直接用“,”分割
spring.kafka.bootstrap-servers=192.168.13.192:9092

总结
这里，zipkin展示的信息，其实不是直接来自于微服务客户端，而是客户端先将数据推送到kafka，然后zipkin再异步的消费这些信息。无论是客户端还是服务端，在指定kafka的时候，都不需要指定topic，会自动将信息推送到kafka中名为zipkin的主题上。
信息倒是消费了，但是kafka并不管存储这些信息，所有这个时候需要把这些信息存储起来，便于日后查看。这些信息可以存储于内存（测试用，重启zipkin后就没有了），MySql等，这里采用的是Elasticsearch来持久化数据存储。


##sleuth+zipkin+kafka+logstash链路追踪二次开发方案 
https://shared-code.com/article/127

##sleuth + kafka + zipkin
https://blog.csdn.net/u012965203/article/details/100006531

##一文搞懂基于zipkin的分布式追踪系统原理与实现
https://blog.csdn.net/weixin_34138255/article/details/91474826

前言
传统单机系统在使用过程中，如果某个请求响应过慢或是响应出错，开发人员可以清楚知道某个请求出了问题，查看日志可以定位到具体方法。但是在分布式系统中，倘若客户端一个请求到达服务器后，由多个服务协作完成。比如：服务A调用服务B，服务B又调用服务C和服务D，服务D又调用服务E，那么想要知道是哪个服务处理时间过长或是处理异常导致这个请求响应缓慢或中断的话，就需要开发人员一个服务接一个服务的去机器上查看日志，先定位到出问题的服务，再定位出问题的具体地方。试想一下，随着系统越来越壮大，服务越来越多，一个请求对应处理的服务调用链越来越长，这种排查方式何其艰难。为了解决这种问题，便诞生了各种分布式场景中追踪问题的解决方案，zipkin就是其中之一。
整体结构长啥样
一个独立的分布式追踪系统，客户端存在于应用中（即各服务中），应具备追踪信息生成、采集发送等功能，而服务端应该包含以下基本的三个功能：
信息收集：用来收集各服务端采集的信息，并对这些信息进行梳理存储、建立索引。
数据存储：存储追踪数据。
查询服务：提供查询请求链路信息的接口。
zipkin 整体结构图如下： 


zipkin(服务端)包含四个组件，分别是collector、storage、search、web UI。
collector 就是信息收集器,作为一个守护进程，它会时刻等待客户端传递过来的追踪数据，对这些数据进行验证、存储以及创建查询需要的索引。
storage 是存储组件。zipkin 默认直接将数据存在内存中，此外支持使用Cassandra、ElasticSearch 和 Mysql。
search 是一个查询进程，它提供了简单的JSON API来供外部调用查询。
web UI 是zipkin的服务端展示平台，主要调用search提供的接口，用图表将链路信息清晰地展示给开发人员。
zipkin的客户端主要负责根据应用的调用情况生成追踪信息，并且将这些追踪信息发送至zipkin由收集器接收。各语言支持均不同，具体可以查看zipkin官网,java语言的支持就是brave。上面结构图中，有追踪器就是指集成了brave。
基本概念了解下
在使用zipkin之前，先了解一下Trace和Span这两个基本概念。一个请求到达应用后所调用的所有服务所有服务组成的调用链就像一个树结构（如下图），我们追踪这个调用链路得到的这个树结构可以称之为Trace。 

在一次Trace中，每个服务的每一次调用，就是一个基本工作单元，就像上图中的每一个树节点，称之为span。每一个span都有一个id作为唯一标识，同样每一次Trace都会生成一个traceId在span中作为追踪标识，另外再通过一个parentId标明本次调用的发起者（就是发起者的span-id）。当span有了上面三个标识后，就可以很清晰的将多个span进行梳理串联，最终归纳出一条完整的跟踪链路。此外，span还会有其他数据，比如：名称、节点上下文、时间戳以及K-V结构的tag信息等等（Zipkin v1核心注解如“cs”和“sr”已被Span.Kind取代，详情查看zipkin-api，本文会在入门的demo介绍完后对具体的Span数据模型进行说明）。

具体怎么追踪的
追踪器位于应用程序上，负责生成相关ID、记录span需要的信息，最后通过传输层传递给服务端的收集器。我们首先思考下面几个问题：
每个span需要的基本信息何时生成？
哪些信息需要随着服务调用传递给服务提供方？
什么时候发送span至zipkin 服务端？
以何种方式发送span?
一个 span 表示一次服务调用，那么追踪器必定是被服务调用发起的动作触发，生成基本信息，同时为了追踪服务提供方对其他服务的调用情况，便需要传递本次追踪链路的traceId和本次调用的span-id。服务提供方完成服务将结果响应给调用方时，需要根据调用发起时记录的时间戳与当前时间戳计算本次服务的持续时间进行记录，至此这次调用的追踪span完成，就可以发送给zipkin服务端了。但是需要注意的是，发送span给zipkin collector不得影响此次业务结果，其发送成功与否跟业务无关，因此这里需要采用异步的方式发送，防止追踪系统发送延迟与发送失败导致用户系统的延迟与中断。下图就表示了一次http请求调用的追踪流程（基于zipkin官网提供的流程图）： 

可以看出服务A请求服务B时先被追踪器拦截，记录tag信息、时间戳，同时将追踪标识添加进http header中传递给服务B，在服务B响应后，记录持续时间，最终采取异步的方式发送给zipkin收集器。span从被追踪的服务传送到Zipkin收集器有三种主要的传送方式：http、Kafka以及Scribe（Facebook开源的日志收集系统）。

1分钟安装zipkin
上文对基于zipkin实现分布式追踪系统的原理做了全面的说明，这里简单介绍一下zipkin的安装方法，下载jar包，直接运行。简单粗暴，但要注意必须jdk1.8及以上。其余两种安装方式见官方介绍。

wget -O zipkin.jar 'https://search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec'

java -jar zipkin.jar

复制代码
启动成功后，打开浏览器访问zipkin的webUI，输入http://ip:9411/,显示页面如下图。具体使用后面介绍。 

##部署Zipkin分布式性能追踪日志系统的操作记录
https://blog.csdn.net/weixin_33796205/article/details/85818639



##Zipkin官网
https://zipkin.io/pages/tracers_instrumentation.html

##Zipkin实践：Python项目中跟踪系统导入Zipkin
https://blog.csdn.net/liumiaocn/article/details/80657943

##dd-opentracing-cpp 
https://github.com/DataDog/dd-opentracing-cpp

Datadog OpenTracing C++ Client
Usage
Usage docs are on the main Datadog website:
NGINX
Envoy
Istio
C++ code
For some quick-start examples, see the examples folder.
Contributing
Before considering contributions to the project, please take a moment to read our brief contribution guidelines.
Build and Test
Dependencies
Building this project requires the following tools installed:
Build tools (eg. build-essential, xcode)
cmake >= 3.1
Additional libraries are installed via a script.
Build Steps
Clone the repository
git clone https://github.com/DataDog/dd-opentracing-cpp
Install additional library dependencies (requires sudo)
cd dd-opentracing-cpp
sudo scripts/install_dependencies.sh
Generate build files using cmake
mkdir .build
cd .build
cmake ..
Run the build
make
(Optional) Run the tests
cmake -DBUILD_TESTING=ON ..
make
ctest --output-on-failure
(Optional) Install in /usr/local
make install
If you want sanitizers to be enabled, then add either the -DSANITIZE_THREAD=ON -DSANITIZE_UNDEFINED=ON or -DSANITIZE_ADDRESS=ON flags to cmake, running the tests will now also check with the sanitizers.
Integration tests
Integration tests require additional tools installed:
msgpack-cli
wiremock
jq
Installation details can be extracted from the Dockerfile for the container that is usually used when running integration tests.
The script below will run the integration tests directly.
test/integration/run_integration_tests_local.sh

##openzipkin /zipkin testdata
https://github.com/openzipkin/zipkin/tree/master/zipkin-lens/testdata

$ curl -X POST -s localhost:9411/api/v2/spans -H'Content-Type: application/json' -d @netflix.json
$ open 'http://localhost:9411/zipkin/?lookback=custom&startTs=1'


##深入探究ZIPKIN调用链跟踪——链路上报篇
https://www.jianshu.com/p/17ce989e108e

1、如果自己写一个上ZIPKIN客户端，该如何写？
分析：要上传数据给服务端，那么必须要搞清楚，ZIPKIN服务端可以接受什么样格式的数据？支持的编码解码协议是什么？还有支持那些通信传输协议？
Task: 了解了服务怎么接收数据后，客户端的task也就明确了：
1）以ZIPKIN服务端支持的数据格式组织数据；
2）以ZIPKIN服务端支持的编解码协议编码数据；
3）以ZIPKIN服务端支持的传输协议上报数据。
2、基础ZIPKIN客户端完成后，如何适配各种组件？
描述：一个服务通常涉及多个组件，包括服务框架，消息中间件，各种数据库等，那么怎么上报这些组件的数据给服务端了，值得我们思考？
分析：其实最简单的方法就是采用一个装饰者模式包装一下组件接口，在其中加入上报的逻辑，但是这种方法局限很大，不灵活。除此之外，我们或许我们可以利用下拦截器技术，AOP技术，以及Agent，探针等技术做到无侵入上报数据。
服务端如何接收数据的？
要想自己写一个ZIPKIN客户端，必须搞清楚ZIPKIN服务端是怎么接收数据的，包括数据格式协议是怎样的？编解码协议是怎样的？还有支持那么传输协议？
ZIPKIN支持的数据格式是怎样的？
ZIPKIN是兼容OpenTracing标准的，OpenTracing规定，每个Span包含如下状态：
操作名称
起始时间
结束时间
一组 KV 值，作为阶段的标签（Span Tags）
阶段日志（Span Logs）
阶段上下文（SpanContext），其中包含 Trace ID 和 Span ID
引用关系（References）
OpenTracing规范与zipkin对应关系如下：
OpenTracing
ZIPKIN
操作名称
name
起始时间
timestamp
结束时间
timestamp+duration
标签
tags
Span上下文
traceId; id
引用关系
parentId
Span日志
无
除此之外，ZIPKIN SAPN还增加了其他几个字端：
字端
描述
Kind kind
Spanl类型，比如是Server还是Client
Annotaion
表示某个时间点发生的Event,Event类型：cs：Client Send 请求；sr：Server Receive到请求；ss：Server 处理完成、并Send Response；cr：Client Receive 到响应
Endpoint localEndpoint
描述本地服务信息，比如服务名，ip等，方便根据服务名检索链路
Endpoint remoteEndpoint
RPC调用时，描述远程服务的服务信息
最终，包含兼容OpenTracing标准的字端，以及其本身的一些字端后，zipkin的span数据字端如下：


##Spring Cloud之zipkin日志文件化
https://blog.csdn.net/yaowwwww7071/article/details/85999153

 方案背景

Zipkin 作为一个链路跟踪工具，用来在微服务中记录每个链路调用的用时情况，链接调用情况包括：

（1）服务作为客户端从发起请求（cs）到收到响应（cr）的时间。

该情况一般在zuul网关或者存在一个服务调用另一个的时间存在。

（2）服务作为服务端从接收到请求(sr)到把将结果发送给客户端的时间（ss，即outputStream flush前的时间）。

一般来说，如果涉及一个服务调用另一个服务，则一次请求会产生至少两条json格式的日志。不涉及到调用其它服务的服务，则会产生一条日志。对于所产生的日志，通过异步http请求的方式发送到zipkin server中进行入库或存到zipkin server的缓存中。之后便可以通过zipkin server进行调用链的分析及跟踪。

基于以上的分析，如果基于默认的解决方案，调用量大的情况下，会导致带来以下问题：

（1）对于zipkin server来说，可能会由于频繁的接收数据而变慢或者直接瘫痪。

（2）对于zipkin client来说（微服务使用端），如果zipkin server响应不及时会导致异步的日志发送请求堆积。堆积会带来对内存的消耗，另外当堆积满了，会导致日志丢失。

（3）发送日志大小的限制。在默认的实现中（HttpZipkinSpanReporter），对于发送日志的数据量有限制大小（5 * 1024 * 1024）。如果日志量超过，则会丢失该日志。

（4）如果zipkin server挂了，会导致大量的数据丢失，还会使得zipkin client由于尝试连接zipkin server端而变得慢。

（5）如果对zipkin client产生的影响，就会影响到业务的正常访问。

基于上述分析，我们需要一种不会导致日志缺失并且对业务访问影响最小的方案。

实现分析

要达到不会导致日志缺失并且对业务访问影响最小，最简单的方式便是将zipkin的日志写到日志文件中。之后再通过分布式日志收集工具将日志收集起来。当需要看某个日志id的调用链路时，我们再通过日志收集工具把相关数据找出，然后用数据导入的方式将日志导致到zipkin servier中。最后，我们便可以利用zipkin server进行调用链路的分析了。

如何实现zipkin日志文件化
通过分析zipkin的日志发送机制，发现其主要是通过实现ZipkinSpanReporter接口的HttpZipkinSpanReporter来发送。而HttpZipkinSpanReporter在自动化配置中为以下：



注意，ConditionalOnMissingBean，这是条件化配置，意思是说当没有存在指定类型的bean（ZipkinSpanReporter）才会实例化该bean。因此，我们可以通过实现ZipkinSpanReporter接口的方式，在实现中通过写日志的方式来将日志写到文件中。

如何将zipkin日志收集起来
可以采用 logstash（日志收集）+ElasticSearch（数据存储）。当日志收集起来后，便可以通过elasticsearch 的HTTP RESTful API，根据日志id查询相关的数据。

如何将zipkin日志导入到zipkin server中 
将日志中json格式的数据，通过HttpZipkinSpanReporter来向zipkin server进行数据导入。

方案实施

在接口实现中，将要记录的数据序列化成json格式，然后记录到日志文件中。



 源码：

package com.yao.springcloud.sleuth;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.cloud.sleuth.zipkin.ZipkinSpanReporter;
import zipkin.Span;
 
public class TraceZipkinSpanReporter implements ZipkinSpanReporter {
    private Logger LOGGER = LoggerFactory.getLogger(TraceZipkinSpanReporter
            .class);
    @Override
    public void report(Span span) {
        if(span != null){
            LOGGER.info(span.toString());
        }
    }
}

将日志数据导入zipkin server
spring-cloud-sleuth-zipkin提供了一个将日志导入zipkin server的方式，即HttpZipkinSpanReporter。我们只需要做以下事情：
（1）将zipkin 日志内容转换成HttpZipkinSpanReporter的发送对象。
（2）调用HttpZipkinSpanReporter进行发送。


##zipkin trace数据结构说明（四） 
https://shared-code.com/article/105


##大规模分布式系统的跟踪系统：Dapper设计给我们的启示
https://blog.csdn.net/liumiaocn/article/details/80657661


##Zipkin实践：Python项目中跟踪系统导入Zipkin
https://blog.csdn.net/liumiaocn/article/details/80657943

##几种分布式调用链监控组件的实践与比较（一）实践
https://www.jianshu.com/p/7f6654657417

##分布式系统调用链监控 
https://www.iteye.com/blog/zhaoshijie-2407600
