#调用链
#cat
[cat]https://github.com/dianping/cat/

#GRPC java 分布式调用链跟踪实践
https://www.jianshu.com/p/2ec0f8d4ae3d

在跟踪链中有以下几个比较重要的数据结构和概念：
span：标识一次分布式调用，其自身包含了id，parentId(指向上级Span的id)， traceIds，服务名称等重要属性，其应尽量保持精简；
trace：标识整个请求链，即一些列Span的组合。其自身的ID将贯穿整个调用链，其中的每个Span都必须携带这个traceId，因此traceId将在整个调用链中传递；
cs：客户端发起请求，标志Span的开始；
sr：服务端接收到请求，并开始处理内部事务，其中sr - cs则为网络延迟和时钟抖动；
ss：服务端处理完请求，返回响应内容，其中ss - sr则为服务端处理请求耗时；
cr：客户端接收到服务端响应内容，标志着Span的结束，其中cr - ss则为网络延迟和时钟抖动。
客户端调用时间=cr-cs
服务端处理时间=sr-ss

#OpenTracing
https://www.jianshu.com/p/d2b11c079af0
https://studygolang.com/articles/13583

#Jaeger
## 分布式追踪OpenTracing与 Jaeger 实现  
https://github.com/jaegertracing/jaeger-client-cpp
https://blog.csdn.net/m0_37598953/article/details/88760603
https://www.kancloud.cn/idzqj/customer/1691930

##jaeger 使用初探
https://www.cnblogs.com/chopper-poet/p/10743141.html

##Linux下从零开始部署和使用Jaeger
https://www.jianshu.com/p/e224b5871998

##全链路监控Jaeger搭建实战
https://www.jianshu.com/p/ffc597bb4ce8

##基于jaeger微服务调用链实现方案
https://cloud.tencent.com/developer/article/1494063

#ZipKin
##ZipKin原理学习--ZipKin入门介绍
Zipkin是一款开源的分布式实时数据追踪系统（Distributed Tracking System），基于 Google Dapper的论文设计而来，由 Twitter 公司开发贡献。其主要功能是聚集来自各个异构系统的实时监控数据。分布式跟踪系统还有其他比较成熟的实现，例如：Naver的Pinpoint、Apache的HTrace、阿里的鹰眼Tracing、京东的Hydra、新浪的Watchman，美团点评的CAT，skywalking等。
ZipKin架构
    ZipKin可以分为两部分，一部分是zipkin server，用来作为数据的采集存储、数据分析与展示；zipkin client是zipkin基于不同的语言及框架封装的一些列客户端工具，这些工具完成了追踪数据的生成与上报功能

Zipkin Server主要包括四个模块：
（1）Collector 接收或收集各应用传输的数据
（2）Storage 存储接受或收集过来的数据，当前支持Memory，MySQL，Cassandra，ElasticSearch等，默认存储在内存中。
（3）API（Query） 负责查询Storage中存储的数据，提供简单的JSON API获取数据，主要提供给web UI使用
（4）Web 提供简单的web界面
 
 Instrumented client和server是分别使用了ZipKin Client的服务，Zipkin Client会根据配置将追踪数据发送到Zipkin  Server中进行数据存储、分析和展示。
ZipKin几个概念
    在追踪日志中，有几个基本概念spanId、traceId、parentId
    traceId：用来确定一个追踪链的16字符长度的字符串，在某个追踪链中保持不变。
    spanId：区域Id，在一个追踪链中spanId可能存在多个，每个spanId用于表明在某个服务中的身份，也是16字符长度的字符串。
    parentId：在跨服务调用者的spanId会传递给被调用者，被调用者会将调用者的spanId作为自己的parentId，然后自己再生成spanId。


##微服务调用链追踪中心搭建  ZIPKIN
https://www.jianshu.com/p/da80ea881424

##个推基于 Zipkin 的分布式链路追踪实践 
https://www.cnblogs.com/evakang/p/10951616.html

##ZIPKIN官网
https://zipkin.io/

##ZIPKIN github
https://github.com/openzipkin/zipkin

##ZIPKIN的搭建使用过程
https://blog.csdn.net/m15231417197/article/details/81540829
（描述可能不是很准确，多多包涵）zipkin类似于日志的高级版，跟踪监控,监控每一次请求链。
zipkin的一些理解：
cs   Client Send 客户端发起请求
sr   Server Receive 服务器接收请求，开始处理
ss   Server Send 服务器完成处理，给客户端应答
cr   Client Receive 客户端接受应答从服务器

traceId：标记一次请求的跟踪，相关的Spans都有相同的traceId；
id：span id；
name：span的名称，一般是接口方法的名称；
parentId：可选的id，当前Span的父Span id，通过parentId来保证Span之间的依赖关系，如果没有parentId，表示当前Span为根Span；
timestamp：Span创建时的时间戳，使用的单位是微秒（而不是毫秒），所有时间戳都有错误，包括主机之间的时钟偏差以及时间服务重新设置时钟的可能性，
出于这个原因，Span应尽可能记录其duration；
duration：持续时间使用的单位是微秒（而不是毫秒）；
annotations：注释用于及时记录事件；有一组核心注释用于定义RPC请求的开始和结束；

cs:Client Send，客户端发起请求；sr:Server Receive，服务器接受请求，开始处理；ss:Server Send，服务器完成处理，给客户端应答；cr:Client Receive，客户端接受应答从服务器；

binaryAnnotations：二进制注释，旨在提供有关RPC的额外信息。

其实就是描述了一次请求的详细信息这些，比如时间等，如果请求失败（报bug或者服务器当掉），就可以通过zipkin来查看请求是执行到了哪一台服务器后失败的，从而得知哪台服务器有问题或者是出bug了。

若要查看zipkin面板其他属性的含义可以查看此博客：
https://segmentfault.com/a/1190000012342007

此过程是使用idea创建的。
共需要创建四个项目：
eurekaserver      注册中心
zipkin-service     本文核心内容zipkin
product-service   服务提供
order-service       服务调用

##ZIPKIN
https://blog.csdn.net/qq_27384769/article/details/84965170

概述
zipkin为分布式链路调用监控系统，聚合各业务系统调用延迟数据，达到链路调用监控跟踪。
在复杂的调用链路中假设存在一条调用链路响应缓慢，如何定位其中延迟高的服务呢？
日志： 通过分析调用链路上的每个服务日志得到结果

zipkin：使用zipkin的web UI可以一眼看出延迟高的服务

zipkin
zipkin主要涉及四个组件 collector storage search web UI

Collector接收各service传输的数据
Cassandra作为Storage的一种，也可以是mysql等，默认存储在内存中，配置cassandra可以参考这里
Query负责查询Storage中存储的数据,提供简单的JSON API获取数据，主要提供给web UI使用

Web 提供简单的web界面

使用zipkin涉及几个概念

1. Span:基本工作单元，一次链路调用(可以是RPC，DB等没有特定的限制)创建一个span，通过一个64位ID标识它， 
span通过还有其他的数据，例如描述信息，时间戳，key-value对的(Annotation)tag信息，parent-id等,其中parent-id 
可以表示span调用链路来源，通俗的理解span就是一次请求信息

2. Trace:类似于树结构的Span集合，表示一条调用链路，存在唯一标识

3. Annotation: 注解,用来记录请求特定事件相关信息(例如时间)，通常包含四个注解信息

cs - Client Start,表示客户端发起请求
sr - Server Receive,表示服务端收到请求
ss - Server Send,表示服务端完成处理，并将结果发送给客户端
cr - Client Received,表示客户端获取到服务端返回信息

4. BinaryAnnotation:提供一些额外信息，一般已key-value对出现

##zipkin c/c++库编译及环境搭建
https://blog.csdn.net/upsuperman/article/details/78049411

##C++ opentracing zipkin 
https://www.cnblogs.com/resibe-3/p/8628561.html

github https://github.com/opentracing/opentracing-cpp
Compile and install
Linux/MacOS
mkdir .build
cd .build
cmake ..
make
sudo make install

make test

cmake https://blog.csdn.net/qq_34935373/article/details/90266958
下载cmake
wget https://cmake.org/files/v3.9/cmake-3.9.2.tar.gz
解压文件
tar zxvf  cmake-3.9.2.tar.gz
cd cmake-3.9.2
./configure
make
sudo make install

vim /etc/profile
在文件末尾处增加以下代码
export PATH=$PATH:/opt/cmake-3.9.2/bin
source /etc/profile

cmake --version

##ZipKin原理学习--ZipKin入门介绍
https://blog.csdn.net/qq924862077/article/details/80285536

##调用追踪存储展示应用——zipkin环境搭建
https://blog.csdn.net/upsuperman/article/details/78048972

##分布式跟踪系统（一）：Zipkin的背景和设计
https://blog.csdn.net/manzhizhen/article/details/52811600

##分布式跟踪系统（二）：Zipkin的Span模型
https://blog.csdn.net/manzhizhen/article/details/53865368?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-2

##zipkin trace数据结构说明（四） 
https://shared-code.com/article/105

##Zipkin 简单分析
https://blog.csdn.net/xsj34567/article/details/80939622

##ZIPKIN的搭建使用过程
https://blog.csdn.net/m15231417197/article/details/81540829

##SpringCloud微服务监控——zipkin：微服务链路跟踪
https://blog.csdn.net/fyk844645164/article/details/98746821

直接到官方地址下载相应的jar包就可以了。这里我下载的是zipkin-server-2.15.0-exec.jar。
编写启动脚本
在官方的文档中zipkin-server，介绍了如何配置。在这里，我们配置一个基于ELK的链路收集：
@echo off  
START "zipkin-server" java -Xmx256m -Xms256m -Xss256k -DKAFKA_BOOTSTRAP_SERVERS=192.168.xx.xxx:9092 -DSTORAGE_TYPE=elasticsearch -DES_HOSTS=192.168.xx.xxx:9200 -jar zipkin-server-2.15.0-exec.jar --server.port=9005
pause

客户端
引入jar包
在原有的spring boot项目中，引入jar包：
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

添加配置文件
在spring boot项目的application.properties文件中，加入配置：

将采样比例1.0是全部都采集，默认是0.1
spring.sleuth.sampler.probability=1.0
spring.zipkin.sender.type=kafka

zipkin里看到的的service name
spring.zipkin.service.name=${spring.application.name}

集群的情况直接用“,”分割
spring.kafka.bootstrap-servers=192.168.13.192:9092

总结
这里，zipkin展示的信息，其实不是直接来自于微服务客户端，而是客户端先将数据推送到kafka，然后zipkin再异步的消费这些信息。无论是客户端还是服务端，在指定kafka的时候，都不需要指定topic，会自动将信息推送到kafka中名为zipkin的主题上。
信息倒是消费了，但是kafka并不管存储这些信息，所有这个时候需要把这些信息存储起来，便于日后查看。这些信息可以存储于内存（测试用，重启zipkin后就没有了），MySql等，这里采用的是Elasticsearch来持久化数据存储。


##sleuth+zipkin+kafka+logstash链路追踪二次开发方案 
https://shared-code.com/article/127

##sleuth + kafka + zipkin
https://blog.csdn.net/u012965203/article/details/100006531

