##ETCD 与 服务发现
https://www.jianshu.com/p/3bd041807974

1. 什么是ETCD
A highly-available key value store for shared configuration and service discovery.
用于配置共享和服务发现的键值存储系统，其四个核心特点：

简单：基于HTTP+JSON的API让你用curl命令就可以轻松使用。

安全：可选SSL客户认证机制。

快速：每个实例每秒支持一千次写操作。

可信：使用Raft算法充分实现了分布式。

2.  ETCD架构

图-2 ETCD组成结构图

HTTP Server：用于处理用户发送的API请求以及其它etcd节点的同步与心跳信息请求。

Store：用于处理etcd支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等等，是etcd对用户提供的大多数API功能的具体实现。

Raft：Raft强一致性算法的具体实现，是etcd的核心。

WAL：Write Ahead Log（预写式日志），是etcd的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd就通过WAL进行持久化存储。WAL中，所有的数据提交前都会事先记录日志。Snapshot是为了防止数据过多而进行的状态快照；Entry表示存储的具体日志内容。
通常，一个用户的请求发送过来，会经由HTTP Server转发给Store进行具体的事务处理，如果涉及到节点的修改，则交给Raft模块进行状态的变更、日志的记录，然后再同步给别的etcd节点以确认数据提交，最后进行数据的提交，再次同步。

2.3 ETCD接口
ETCD提供HTTP协议，在最新版本中支持Google gRPC方式访问。具体支持接口情况如下：
    a. ETCD是一个高可靠的KV存储系统，支持PUT/GET/DELETE接口；
    b. 为了支持服务注册与发现，支持WATCH接口（通过http long poll实现）；
    c. 支持KEY持有TTL属性；
    d. CAS（compare and swap)操作;
    e. 支持多key的事务操作；
    f.  支持目录操作
    
3. 应用场景
场景一：服务发现（Service Discovery）
服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听udp或tcp端口，并且通过名字就可以查找和连接。

3. 应用场景
场景一：服务发现（Service Discovery）
服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听udp或tcp端口，并且通过名字就可以查找和连接。


图-1 服务发现示意图
微服务协同工作架构中，服务动态添加。随着Docker容器的流行，多种微服务共同协作，构成一个相对功能强大的架构的案例越来越多。透明化的动态添加这些服务的需求也日益强烈。通过服务发现机制，在etcd中注册某个服务名字的目录，在该目录下存储可用的服务节点的IP。在使用服务的过程中，只要从服务目录下查找可用的服务节点去使用即可。


图2 微服务协同工作
场景二：消息发布与订阅
在分布式系统中，最适用的一种组件间通信方式就是消息发布与订阅。即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到分布式系统配置的集中式管理与动态更新。


图3 消息发布与订阅
场景三：分布式通知与协调
这里说到的分布式通知与协调，与消息发布和订阅有些相似。都用到了etcd中的Watcher机制，通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。实现方式通常是这样：不同系统都在etcd上对同一个目录进行注册，同时设置Watcher观测该目录的变化（如果对子目录的变化也有需要，可以设置递归模式），当某个系统更新了etcd的目录，那么设置了Watcher的系统就会收到通知，并作出相应处理。
场景四：分布式锁
因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。
保持独占即所有获取锁的用户最终只有一个可以得到。etcd为此提供了一套实现分布式锁原子操作CAS（CompareAndSwap）的API。通过设置prevExist值，可以保证在多个节点同时去创建某个目录时，只有一个成功。而创建成功的用户就可以认为是获得了锁。
控制时序，即所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。etcd为此也提供了一套API（自动创建有序键），对一个目录建值时指定为POST动作，这样etcd会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。同时还可以使用API按顺序列出所有当前目录下的键值。此时这些键的值就是客户端的时序，而这些键中存储的值可以是代表客户端的编号。


4. ETCD VS ZooKeeper

一致性协议： ETCD使用[Raft]协议， ZK使用ZAB（类PAXOS协议），前者容易理解，方便工程实现；

运维方面：ETCD方便运维，ZK难以运维；

项目活跃度：ETCD社区与开发活跃，ZK已经快死了；

API：ETCD提供HTTP+JSON, gRPC接口，跨平台跨语言，ZK需要使用其客户端；

访问安全方面：ETCD支持HTTPS访问，ZK在这方面缺失。

##ETCD高可用特性学习 

只有当集群中多数节点正常的情况下，才可以进行运行时的配置管理。如果集群多数节点损坏，集群就失去了写入数据的能力。官方推荐3，5，7为etcd cluster数目，其中7可以满足大部分情况
 
通常情况下，如果是Follower节点宕机，如果剩余可用节点数量超过半数，集群可以几乎没有影响的正常工作。如果是Leader节点宕机，那么Follower就收不到心跳而超时，发起竞选获得投票，成为新一轮term的Leader，继续为集群提供服务。 
在最初启动etcd集群时，发现核心节点的数量已经满足要求时，多余的自动启用Proxy模式，若核心节点挂掉，proxy模式的节点并不会转化为普通节点，etcd目前没有任何机制会自动去变化整个集群总共的节点数量
 
 
节点迁移和替换
当你节点所在的机器出现硬件故障，或者节点出现如数据目录损坏等问题，导致节点永久性的不可恢复时，就需要对节点进行迁移或者替换。当一个节点失效以后，必须尽快修复，因为etcd集群正常运行的必要条件是集群中多数节点都正常工作。
 
迁移一个节点需要进行四步操作：

暂停正在运行着的节点程序进程

把数据目录从现有机器拷贝到新机器

使用api更新etcd中对应节点指向机器的url记录更新为新机器的ip

使用同样的配置项和数据目录，在新的机器上启动etcd
 
在最初启动etcd集群时，发现核心节点的数量已经满足要求时，多余的自动启用Proxy模式，若核心节点挂掉，proxy模式的节点并不会转化为普通节点
 
灾难恢复
当集群超过半数的节点都失效时，就需要通过手动的方式，ectd提供了一套备份数据并无损重建cluster 的方法 
 
备份数据到新机器
利用数据和 -force-new-cluster重新创建一个单node集群
修改peer url将其他节点加入
 
 为了最大化集群的安全性，一旦有任何数据损坏或丢失的可能性，你就应该把这个节点从集群中移除，然后加入一个不带数据目录的新节点。
 
 
##etcd集群搭建（高可用） 
https://www.cnblogs.com/51wansheng/p/10234036.html

##利用 etcd 进行 leader 选举实现服务高可用 
https://segmentfault.com/a/1190000020850802

概述
Etcd 是什么？
Etcd是一个分布式的，一致的key-value存储，主要用于共享配置和服务发现。Etcd是由CoreOS开发并维护，通过Raft一致性算法处理日志复制以保证强一致性。Raft是一个来自Stanford的新的一致性算法，适用于分布式系统的日志复制，Raft通过选举的方式来实现一致性，在Raft中，任何一个节点都可能成为leader。Google的容器集群管理系统Kubernetes、开源PaaS平台Cloud Foundry和CoreOS的Fleet都广泛使用了etcd。

Etcd 的特性？
在分布式系统中，如何管理节点间的状态一直是一个难题，etcd像是专门为集群环境的服务发现和注册而设计，它提供了数据TTL失效、数据改变监视、多值、目录监听、分布式锁原子操作等功能，可以方便的跟踪并管理集群节点的状态。Etcd的特性如下：
简单: curl可访问的用户的API（HTTP+JSON）
安全: 可选的SSL客户端证书认证
快速: 单实例每秒1000次写操作
可靠: 使用Raft算法保证一致性

为什么需要 Etcd？
所有的分布式系统，都面临的一个问题是多个节点之间的数据共享问题，这个和团队协作的道理是一样的，成员可以分头干活，但总是需要共享一些必须的信息，比如谁是leader， 都有哪些成员，依赖任务之间的顺序协调等。所以分布式系统要么自己实现一个可靠的共享存储来同步信息（比如Elasticsearch），要么依赖一个可靠的共享存储服务，而Etcd就是这样一个服务。

Etcd主要提供以下能力:
提供存储以及获取数据的接口，它通过协议保证etcd集群中的多个节点数据的强一致性。用于存储元信息以及共享配置。
提供监听机制，客户端可以监听某个key或者某些key的变更（v2和v3的机制不同）。用于监听和推送变更。
提供key的过期以及续约机制，客户端通过定时刷新来实现续约（v2和v3的实现机制也不一样）。用于集群监控以及服务注册发现。
提供原子的CAS（Compare-and-Swap）和CAD（Compare-and-Delete）支持（v2通过接口参数实现，v3通过批量事务实现）。用于分布式锁以及leader选举。

第三方库和客户端工具
目前有很多支持etcd的库和客户端工具，比如命令行客户端工具etcdctl、Go客户端go-etcd、Java客户端jetcd、Python客户端python-etcd等等。

背景
回归正题，一起谈谈如何借助etcd进行leader选举实现高可用吧。
首先说下背景，现在集群上有一个服务，我希望它是高可用的，当一个节点上的这个服务挂掉之后，另一个节点就会起一个同样的服务，从而保证服务不中断。
这种场景应该比较常见，比如MySQL高可用、NFS高可用等等，而这些高可用的实现方式往往是通过keepalived、ctdb等组件，对外暴露一个虚拟IP提供服务。

技术选型
那为什么不采用上面提到的技术实现高可用呢？首先这些技术很成熟，的确很好用，但是不适用于所有场景，它们比较适合对外提供读写服务的场景，而并不是所有服务都是对外服务的；其次，在已经存在etcd的集群环境上并且借助etcd可以达到高可用的情况下没有必要再引入其他组件；然后，在第三方库和客户端工具上，etcd有很大优势；最后，因为Raft算法的关系，在一致性上面etcd做的也比上面这几个要好。

核心：TTL & CAS
Etcd进行leader选举的实现主要依赖于etcd自带的两个核心机制，分别是 TTL 和 Atomic Compare-and-Swap。TTL（time to live）指的是给一个key设置一个有效期，到期后这个key就会被自动删掉，这在很多分布式锁的实现上都会用到，可以保证锁的实时有效性。Atomic Compare-and-Swap（CAS）指的是在对key进行赋值的时候，客户端需要提供一些条件，当这些条件满足后，才能赋值成功。这些条件包括：
prevExist：key当前赋值前是否存在
prevValue：key当前赋值前的值
prevIndex：key当前赋值前的Index 
这样的话，key的设置是有前提的，需要知道这个key当前的具体情况才可以对其设置。

设计原理
所以我们可以这样设计：
先定义一个key，用作于选举；定义key对应的value，每个节点定义的value需要能够唯一标识；
定义TTL周期，各节点客户端运行周期为TTL/2，这样可以保证key可以被及时创建或更新；
启动时，每个客户端尝试cas create key，并设置TTL，如果创建不成功，则表示抢占失败；如果创建成功，则抢占成功，并且给key赋值了可以唯一标识自己的value，并设置TTL；
客户端TTL/2定期运行，每个客户端会先get这个key的value，跟自己节点定义的value相比较，如果不同，则表示自己角色是slave，所以接下来要做的事就是周期去cas create key，并设置TTL；如果相同，则表示自己角色是master，那么就不需要再去抢占，只要更新这个key的TTL，延长有效时间；
如果master节点中途异常退出，那么当TTL到期后，其他slave节点则会抢占到并选举出新的master。
具体实现
环境参数：
etcd：v2
client：python-etcd

定义参数
定义存储目录名称为etcd_watcher，etcd_watcher所有相关的key都在该目录下；
定义用于选举的key名称为master，定义每个节点赋该key的值为本节点的hostname用作唯一标识；
定义TTL为60s，这样etcd_watcher定期执行的时间为30s；
定义etcd_watcher六种角色，分别为：
Master：上一次运行角色为Master，当前运行角色仍为Master 
Slave：上一次运行角色为Slave，当前运行角色仍为Slave 
ToMaster：上一次运行角色为Slave，当前运行角色为Master 
ToSlave：上一次运行角色为Master，当前运行角色为Slave 
InitMaster：上一次运行角色为None，当前运行角色为Master 
InitSlave：上一次运行角色为None，当前运行角色为Slave

##etcd实现-全流程分析
https://zhuanlan.zhihu.com/p/135891186


##深入浅出etcd系列 – 心跳和选举 
https://www.cnblogs.com/huaweiyuncce/p/10130522.html

3.2 发送心跳
当集群已经产生了leader，则leader会在固定间隔内给所有节点发送心跳。其他节点收到心跳以后重置心跳等待时间，只要心跳等待不超时，follower的状态就不会改变。 具体的过程如下：

1. 对于leader，tick被设置为tickHeartbeat，tickHeartbeat会产生增长递增心跳过期时间计数(heartbeatElapsed)，如果心跳过期时间超过了心跳超时时间计数(heartbeatTimeout)，它会产生一个MsgBeat消息。

心跳超时时间计数是系统设置死的，就是1。也就是说只要1次tick时间过去，基本上会发送心跳消息。发送心跳首先是调用状态机的step方法。


2. step在leader状态下为stepLeader()，当收到MsgBeat时，它会调用bcastHeartbeat()广播MsgHeartbeat消息。

构造MsgHeartbeat类型消息时，需要在Commit字段填入当前已经可以commit的消息index，如果该index大于peer中记录的对端节点已经同步的日志index，则采用对端已经同步的日志index。Commit字段的作用将在接收端处理消息时详细介绍。

3. 选举消息发送的流程和所有消息的流程一样，不在赘述。

4. 心跳消息到了对端节点以后，进行相应的处理，最终会调到Step方法，进行状态机步进。Step处理MsgVote方法的流程是这样的：
    - 首先，如果选举过期时间还没有超时，将拒绝这次选举请求。这是为了防止有些follower自己的原因没收到leader的心跳擅自发起选举。
    - 如果r.Vote已经设置了，也就是说在一个任期中已经同意了某个节点的选举请求，就会拒绝选举
    - 如果根据消息中的LogTerm和Index，也就是第2步传进来的竞选者的最新日志的index和term，发现竞选者比当前节点的日志要旧，则拒绝选举。
    - 其他情况则赞成选举。回复一个赞成的消息。

5. 竞选者收到MsgVoteResp消息以后，stepCandidate处理该消息，首先更新r.votes。r.votes是保存了选票信息。如果同意票超过半数，则升级为leader，否则如果已经获得超过半数的反对票，则变成follower。

6、频繁重选举的问题
如果etcd频繁出现重新选举，会导致系统长时间处于不可用状态，大大降低了系统的可用性。

什么原因会导致系统重新选举呢？

1. 网络时延和网络拥塞：

从心跳发送的流程可以看到，心跳消息和其他消息一样都是先放到Ready结构的msgs数组中。然后逐条发送出去，对不同的节点，消息发送不会阻塞。但是对相同的节点，是一个协程来处理它的msgc通道的。也就是说如果有网络拥塞，是有可能出现其他的消息拥塞通道，导致心跳消息不能及时发送的。即使只有心跳消息，拥塞引起信道带宽过小，也会导致这条心跳消息长时间不能到达对端。也会导致心跳超时。另外网络延时会导致消息发送时间过程，也会引起心跳超时。

另外，peer之间通信建链的超时时间设置为1s+(选举超时时间)*1/5 。也就是说如果选举超时设置为5s，那么建链时间必须小于2s。在网络拥塞的环境下，这也会影响消息的正常发送。

2. IO延时：

从apply的流程可以看到，发送msg以后，leader会开始持久化已经commit的日志或者snapshot。

这个过程会阻塞这个协程的调用。如果这个过程阻塞时间过长，就会导致后面的msgs堵在那里不能及时发送。

根据官网的解释，etcd是故意这么做的，这样可以让那些io有问题的leader自动失去leader地位。让io正常的节点选上leader。但是如果整个集群的节点io都有问题，就会导致整个集群不稳定。


