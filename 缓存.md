#leveldb
##leveldb 安装及使用
https://blog.csdn.net/ronon77/article/details/84908778
https://blog.csdn.net/chdhust/article/details/49402989
https://blog.csdn.net/salyty/article/details/83106237
https://blog.csdn.net/chenriwei2/article/details/45178249
https://blog.csdn.net/weixin_42663840/article/details/82253556
https://blog.csdn.net/xiongwenwu/article/details/53262804

##leveldb源码
https://baijiahao.baidu.com/s?id=1634577516618476849&wfr=spider&for=pc
https://www.cnblogs.com/haippy/archive/2011/12/04/2276064.html
http://blog.itpub.net/31561269/viewspace-2375371/
https://yq.aliyun.com/articles/684218?utm_content=g_1000035187
https://github.com/google/leveldb/blob/master/benchmarks/db_bench.cc

##leveldb api
https://blog.csdn.net/qq_32293345/article/details/85063531

#redis
Redis系列八：redis主从复制和哨兵
https://www.cnblogs.com/leeSmall/p/8398401.html 

Redis Cluster流程原理
https://blog.csdn.net/fouy_yun/article/details/81590252  
https://blog.csdn.net/qq2430/article/details/80716313  浅谈Redis Cluster


##Redis-Cluster
美团在Redis上踩过的一些坑-5.redis cluster遇到的一些问题
https://blog.csdn.net/carlosfu/article/details/84749049 
我们从Redis-Cluster beta版 RC1~4 到现在的3.0-release均没有遇到什么大问题（线上维护600个实例）。

redis cluster 扩容
https://segmentfault.com/a/1190000016359421

Redis集群节点的选举（实验）
https://blog.51cto.com/13690439/2119973 

Redis Cluster
https://segmentfault.com/a/1190000017578588  

redis cluster 扩容
https://segmentfault.com/a/1190000016359421 

##浅谈Redis中的Rehash机制
https://blog.csdn.net/cqk0100/article/details/80400811  

##Redis五种数据类型
https://blog.csdn.net/zh15732621679/article/details/80614091 

##redis集群核心原理:gossip通信、jedis Smart定位、主备切换
https://blog.csdn.net/r_p_j/article/details/78813265

##《Redis设计与实现总结》
https://blog.csdn.net/qq_39843374/article/details/80979936

##《Redis设计与实现》学习笔记
https://www.cnblogs.com/mengchunchen/p/9025139.html

4.4 rehash（重新散列）
　　随着操作进行，哈希表保存的键值对会增加或减少，为了让哈希表的负载因子（load factor）维持在一个合理范围，当一个哈希表保存的键太多或者太少，需要对哈希表进行扩展或者收缩。扩展或收缩哈希表的过程，就称为rehash。
　　rehash步骤如下：
　　1、给字典的ht[1]申请存储空间，大小取决于要进行的操作，以及ht[0]当前键值对的数量（ht[0].used）。假设当前ht[0].used=x。
　　　　如果是扩展，则ht[1]的值是第一个大于等于x*2的2n的值。例如x是30，则ht[1]的大小是第一个大于等于30*2的2n的值，即64。
　　　　如果是收缩，则ht[1]的值是第一个大于等于x的2n的值。例如x是30，则ht[1]的大小是第一个大于等于30的2n的值，即32。
　　2、将保存在ht[0]上面的所有键值对，rehash到ht[1]，即对每个键重新采用哈希算法的方式计算哈希值和索引值，再放到相应的ht[1]的表格指定位置。
　　3、当ht[0]的所有键值对都rehash到ht[1]后，释放ht[0]，并将ht[1]设置为ht[0]，再新建一个空的ht[1]，用于下一次rehash。
 
　　rehash条件：
　　负载因子（load factor）计算：
　　load_factor =ht[0].used / ht[0].size，即负载因子大小等于当前哈希表的键值对数量，除以当前哈希表的大小。
 
　　扩展：
　　当以下任一条件满足，哈希表会自动进行扩展操作：
　　1）服务器目前没有在执行BGSAVE或者BGREWRITEAOF命令，且负载因子大于等于1。
　　2）服务器目前正在在执行BGSAVE或者BGREWRITEAOF命令，且负载因子大于等于5。


第4章 字典
　　字典，又称符号表、关联数组、映射，是一种保存键值对的抽象数据结构。
　　每个键（key）和唯一的值（value）关联，键是独一无二的，通过对键的操作可以对值进行增删改查。
　　redis中字典应用广泛，对redis数据库的增删改查就是通过字典实现的。即redis数据库的存储，和大部分关系型数据库不同，不采用B+tree进行处理，而是采用hash的方式进行处理。
　　字典还是hash键的底层实现之一。
　　当hash键包含了许多元素，或者元素是比较长的字符串的时候，就会用到字典作为hash键的底层实现。

4.1 字典的实现
redis的字典，底层是使用哈希表实现，每个哈希表有多个哈希节点，每个哈希节点保存了一个键值对。
1、哈希表

 1 /*
 2  * 哈希表
 3  *
 4  * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。
 5  */
 6 typedef struct dictht {
 7     
 8     // 哈希表数组
 9     dictEntry **table;
10 
11     // 哈希表大小
12     unsigned long size;
13     
14     // 哈希表大小掩码，用于计算索引值
15     // 总是等于 size - 1
16     unsigned long sizemask;
17 
18     // 该哈希表已有节点的数量
19     unsigned long used;
20 
21 } dictht;
 
　　其中，table是一个数组，里面的每个元素指向dictEntry（哈希表节点）结构的指针，dictEntry结构是键值对的结构；
　　size表示哈希表的大小，也是table数组的大小；
　　used表示table目前已有的键值对节点数量；
　　sizemask一直等于size-1，该值与哈希值一起决定一个属性应该放到table的哪个位置。
　　大小为4的空哈希表结构如下图（左边一列的图）所示：

3、字典

 1 /*
 2  * 字典
 3  */
 4 typedef struct dict {
 5 
 6     // 类型特定函数
 7     dictType *type;
 8 
 9     // 私有数据
10     void *privdata;
11 
12     // 哈希表
13     dictht ht[2];
14 
15     // rehash 索引
16     // 当 rehash 不在进行时，值为 -1
17     int rehashidx; /* rehashing not in progress if rehashidx == -1 */
18 
19     // 目前正在运行的安全迭代器的数量
20     int iterators; /* number of iterators currently running */
21 
22 } dict;

 
　　type用于存放用于处理特定类型的处理函数；
　　privdata用于存放私有数据，保存传给type内的函数的数据；
　　rehash是一个索引，当没有在rehash进行时，值是-1；
　　ht是包含两个项的数组，每个项是一个哈希表，一般情况下只是用ht[0]，只有在对ht[0]进行rehash时，才会使用ht[1]。

4.2 哈希算法
　　要将新的键值对加到字典，程序要先对键进行哈希算法，算出哈希值和索引值，再根据索引值，把包含新键值对的哈希表节点放到哈希表数组指定的索引上。
　　redis实现哈希的代码是：
　　hash =dict->type->hashFunction(key);
　　index = hash& dict->ht[x].sizemask;
　　算出来的结果中，index的值是多少，则key会落在table里面的第index个位置（第一个位置index是0）。
　　其中，redis的hashFunction，采用的是murmurhash2算法，是一种非加密型hash算法，其具有高速的特点。

4.3 键冲突解决
　　当两个或者以上的键被分配到哈希表数组的同一个索引上，则称这些键发生了冲突。
　　为了解决此问题，redis采用链地址法。被分配到同一个索引上的多个节点可以用单链表连接起来。
　　因为没有指向尾节点的指针，所以总是将新节点加在表头的位置。（O(1)时间）

4.4 rehash（重新散列）
　　随着操作进行，哈希表保存的键值对会增加或减少，为了让哈希表的负载因子（load factor）维持在一个合理范围，当一个哈希表保存的键太多或者太少，需要对哈希表进行扩展或者收缩。扩展或收缩哈希表的过程，就称为rehash。
　　rehash步骤如下：
　　1、给字典的ht[1]申请存储空间，大小取决于要进行的操作，以及ht[0]当前键值对的数量（ht[0].used）。假设当前ht[0].used=x。
　　　　如果是扩展，则ht[1]的值是第一个大于等于x*2的2n的值。例如x是30，则ht[1]的大小是第一个大于等于30*2的2n的值，即64。
　　　　如果是收缩，则ht[1]的值是第一个大于等于x的2n的值。例如x是30，则ht[1]的大小是第一个大于等于30的2n的值，即32。
　　2、将保存在ht[0]上面的所有键值对，rehash到ht[1]，即对每个键重新采用哈希算法的方式计算哈希值和索引值，再放到相应的ht[1]的表格指定位置。
　　3、当ht[0]的所有键值对都rehash到ht[1]后，释放ht[0]，并将ht[1]设置为ht[0]，再新建一个空的ht[1]，用于下一次rehash。
 
　　rehash条件：
　　负载因子（load factor）计算：
　　load_factor =ht[0].used / ht[0].size，即负载因子大小等于当前哈希表的键值对数量，除以当前哈希表的大小。
 
　　扩展：
　　当以下任一条件满足，哈希表会自动进行扩展操作：
　　1）服务器目前没有在执行BGSAVE或者BGREWRITEAOF命令，且负载因子大于等于1。
　　2）服务器目前正在在执行BGSAVE或者BGREWRITEAOF命令，且负载因子大于等于5。
 
　　收缩：
　　当负载因子小于0.1时，redis自动开始哈希表的收缩工作。

4.5 渐进式rehash
　　redis对ht[0]扩展或收缩到ht[1]的过程，并不是一次性完成的，而是渐进式、分多次的完成，以避免如果哈希表中存有大量键值对，一次性复制过程中，占用资源较多，会导致redis服务停用的问题。
　　渐进式rehash过程如下：
　　1、为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两张哈希表。
　　2、将字典中的rehashidx设置成0，表示正在rehash。rehashidx的值默认是-1，表示没有在rehash。
　　3、在rehash进行期间，程序处理正常对字典进行增删改查以外，还会顺带将ht[0]哈希表上，rehashidx索引上，所有的键值对数据rehash到ht[1]，并且rehashidx的值加1。
　　4、当某个时间节点，全部的ht[0]都迁移到ht[1]后，rehashidx的值重新设定为-1，表示rehash完成。
 
　　渐进式rehash采用分而治之的工作方式，将哈希表的迁移工作所耗费的时间，平摊到增删改查中，避免集中rehash导致的庞大计算量。
　　在rehash期间，对哈希表的查找、修改、删除，会先在ht[0]进行。
　　如果ht[0]中没找到相应的内容，则会去ht[1]查找，并进行相关的修改、删除操作。而增加的操作，会直接增加到ht[1]中，目的是让ht[0]只减不增，加快迁移的速度。

4.6 总结
　　字典在redis中广泛应用，包括数据库和hash数据结构。
　　每个字典有两个哈希表，一个是正常使用，一个用于rehash期间使用。
　　当redis计算哈希时，采用的是MurmurHash2哈希算法。
　　哈希表采用链地址法避免键的冲突，被分配到同一个地址的键会构成一个单向链表。
　　在rehash对哈希表进行扩展或者收缩过程中，会将所有键值对进行迁移，并且这个迁移是渐进式的迁移。

##一文看懂 Redis5 搭建集群  
https://my.oschina.net/ruoli/blog/2252393 

Why Redis 4.0?
https://www.liangzl.com/get-article-detail-5391.html

如何提高缓存命中率（Redis）
https://blog.csdn.net/weixin_34238633/article/details/85968131
https://github.com/junegunn/redis-stat

redis命中率不高问题排查
https://blog.csdn.net/h952520296/article/details/84880094

一次Redis问题排查
https://blog.csdn.net/KimmKing/article/details/79815979

redis cluster
https://www.iteye.com/blog/shift-alt-ctrl-2285470

sentinel
https://blog.csdn.net/sanwenyublog/article/details/53385616

redis订阅
https://www.cnblogs.com/kellynic/p/9952386.html

redis raft
https://www.iteye.com/blog/shift-alt-ctrl-2285470

源码原理
https://www.jianshu.com/p/0232236688c1

gossip
https://blog.csdn.net/qq_33814629/article/details/79904158
http://www.imooc.com/article/73798

redis原理及实现
https://www.cnblogs.com/xiufengchen/p/10455288.html

##Redis自己的事件模型 ae
https://www.cnblogs.com/shijingxiang/articles/5369224.html

##raft
http://ifeve.com/raft/
http://ifeve.com/解读raft协议（一-算法基础）/
http://ifeve.com/解读raft（二-选举和日志复制）/
https://www.jianshu.com/p/a5d37ca84f5e
https://www.cnblogs.com/lushilin/p/9268969.html

RAFT算法随想
https://blog.csdn.net/hfty290/article/details/75331948#comments

解读Raft（三 安全性）
https://blog.csdn.net/weixin_33778778/article/details/89588200

##Redis的缓存淘汰策略LRU与LFU
https://www.jianshu.com/p/c8aeb3eee6bc

##Redis基础 常用类型 时间复杂度
https://blog.csdn.net/andy86869/article/details/88366513

RDB
采用RDB 的持久化方式，redis 会定期保存数据快照到一个 rdb 文件中，并在启动时自动加载 rdb文件，恢复之前保存的数据，可以在 redis.conf 中配置 redis 进行快照保存的时机
save [ seconds ] [changes]
意思是在 seconds 秒内如果发生了 changes 次数据修改，则进行一次 RDB 快照保存 
eg.  save 60 100

在 conf 文件中 可以配置多条 save 策略
save 900 1 
save 300 10 
save 60 10000

还可以通过手工 bgsave 命令触发 rdb 快照保存
下面说说 rdb 的优点
对性能影响小 子进程 操作 rdb
每次生成一个完整的 rdb 文件，作为非常可靠的灾难恢复手段
rdb文件恢复数据比 aof 快很多

RDB 缺点是
快照是定期生成的，所以可能干好在 两次 rdb 之间 redis 挂了，那么这个自从上一次到这一次之间的数据，或多或少地会丢失部分数据
如果数据集非常的大 而且 CPU 不够强，Redis 是 fork 子进程时可能会消耗相对较长的时间，因此影响这期间客户端的请求。

AOF
采用 aof 持久化方式，redis 会把每一次的写请求都放在一个日志文件里，redis 重启的时候，会把 aof 文件中的记录的所有的写操作顺序的执行一遍，确保数据恢复到最新
aof 默认是关闭的，需要开启进行如下配置
appendonly yes

aof 提供了 3 中 fsync 配置 always 、everysec 、no
appendfsync no 不进行 fsync 将 flush 文件的时机交给 os 决定，速度最快
appendfsync always 每写入一条日志就进行一次的 fsync 操作，数据安全性最高，单数速度最慢
appendfsync 折中的做法，交给后台线程每秒 fsync 一次

随着 aof 不断的记录写操作日子，必定会出现一些无用的日志，例如某个时间点执行了 set key1 “abc” ，在此之后又执行了 set key1 “bcd”，那么第一条命令显然是没有用的，大量的无用日志会使得 aof 文件过大，也会让数据恢复的时间加长。基于这种情况，redis 提供了 aof rewrite 功能，只保留能够把书恢复到最新状态的最小写操作集。

aof rewrite 命令 可以通过 bgrewriteaof 命令触发，也可以通过 redis 定期自动执行。
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min--size 64mb

两行的含义是  reids 在每次 aof  rewrite 时，会记录rewrite 后 aof 的大小，当 aof 日志
	在该基础上增长了 100% 后，自动进行 aof rewrite 操作，同时如果增长的大小没有达到 64mb
	 则不胡 rewrite

aof 的优点
安全性很高， appendfsync always 时候，任何写入的数据都不会丢失，但是这个策略一般不会使用，太慢了
aof 在发生断电的时候也不会损坏，即使出现某条日志写入一半的情况，也可以使用 redis-check-aof 工具轻松修复
aof 文件易读
aof 的缺点
aof 的文件通常都比 rdb 文件大
性能消耗比 rdb 高
数据恢复比 rdb 慢

##Redis EXISTS命令耗时过长case排查
https://blog.csdn.net/chosen0ne/article/details/50543335

##redis慢查询分析
https://blog.csdn.net/kwy15732621629/article/details/79131137

##使用 Redis 的 slowlog get [n] 慢查询日志彻底解决生产问题！
https://blog.csdn.net/weixin_44018338/article/details/99460667

##Redis 性能问题排查：slowlog 和排队延时
https://blog.csdn.net/weixin_33815613/article/details/92370024


